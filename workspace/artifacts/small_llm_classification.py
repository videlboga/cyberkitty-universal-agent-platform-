#!/usr/bin/env python3
"""
üöÄ –ú–ê–õ–ï–ù–¨–ö–ò–ï –ë–´–°–¢–†–´–ï LLM –î–õ–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –ê–ì–ï–ù–¢–û–í
–ü—Ä–æ—Å—Ç–∞—è –∑–∞–¥–∞—á–∞ = –ø—Ä–æ—Å—Ç–æ–µ —Ä–µ—à–µ–Ω–∏–µ!
"""

import asyncio
import aiohttp
import json
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class SmallLLMProvider:
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –º–∞–ª–µ–Ω—å–∫–∏—Ö LLM"""
    name: str
    api_url: str
    model: str
    cost_per_1k_tokens: float
    avg_response_time_ms: int
    max_tokens: int

class FastAgentClassifier:
    """
    üöÄ –ë—ã—Å—Ç—Ä–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –º–∞–ª–µ–Ω—å–∫–∏–µ LLM
    
    –ü–†–ò–ù–¶–ò–ü: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ - —ç—Ç–æ –ø—Ä–æ—Å—Ç–∞—è –∑–∞–¥–∞—á–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.
    –ù–µ –Ω—É–∂–Ω—ã –º–æ—â–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ç–∏–ø–∞ GPT-4, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–∞–ª–µ–Ω—å–∫–∏—Ö –∏ –±—ã—Å—Ç—Ä—ã—Ö!
    """
    
    def __init__(self):
        self.providers = self._init_providers()
        self.current_provider = "groq"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π
        
        # –ö–µ—à –¥–ª—è —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        self.classification_cache: Dict[str, str] = {}
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.classification_prompt = self._create_classification_prompt()
    
    def _init_providers(self) -> Dict[str, SmallLLMProvider]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –º–∞–ª–µ–Ω—å–∫–∏—Ö LLM"""
        
        return {
            # Groq - —Å–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä—ã–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
            "groq": SmallLLMProvider(
                name="Groq Llama-3.1-8B",
                api_url="https://api.groq.com/openai/v1/chat/completions",
                model="llama-3.1-8b-instant",
                cost_per_1k_tokens=0.0001,  # $0.0001 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤!
                avg_response_time_ms=200,    # 200–º—Å!
                max_tokens=8192
            ),
            
            # Ollama - –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
            "ollama": SmallLLMProvider(
                name="Ollama Llama-3.2-3B",
                api_url="http://localhost:11434/api/generate",
                model="llama3.2:3b",
                cost_per_1k_tokens=0.0,     # –ë–µ—Å–ø–ª–∞—Ç–Ω–æ!
                avg_response_time_ms=300,    # 300–º—Å –Ω–∞ CPU
                max_tokens=4096
            ),
            
            # Together AI - –±—ã—Å—Ç—Ä—ã–µ –º–∞–ª—ã–µ –º–æ–¥–µ–ª–∏
            "together": SmallLLMProvider(
                name="Together Llama-3.2-3B",
                api_url="https://api.together.xyz/v1/chat/completions", 
                model="meta-llama/Llama-3.2-3B-Instruct-Turbo",
                cost_per_1k_tokens=0.0002,
                avg_response_time_ms=250,
                max_tokens=4096
            ),
            
            # OpenAI GPT-4o-mini (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
            "openai": SmallLLMProvider(
                name="OpenAI GPT-4o-mini",
                api_url="https://api.openai.com/v1/chat/completions",
                model="gpt-4o-mini",
                cost_per_1k_tokens=0.00015,
                avg_response_time_ms=800,
                max_tokens=4096
            )
        }
    
    def _create_classification_prompt(self) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        
        return """–¢—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∞–≥–µ–Ω—Ç–æ–≤. –í—ã–±–µ—Ä–∏ –û–î–ù–û–ì–û –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∑–∞–¥–∞—á–∏:

–ê–ì–ï–ù–¢–´:
nova - –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞
sherlock - –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
artemis - –∫–æ–Ω—Ç–µ–Ω—Ç, —Ç–µ–∫—Å—Ç—ã, –¥–∏–∑–∞–π–Ω  
ada - –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, –∫–æ–¥
cipher - –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, —Ç–µ—Å—Ç—ã
warren - —Ñ–∏–Ω–∞–Ω—Å—ã, –¥–µ–Ω—å–≥–∏
viral - –º–∞—Ä–∫–µ—Ç–∏–Ω–≥, —Ä–µ–∫–ª–∞–º–∞

–ó–ê–î–ê–ß–ê: {task}

–û–¢–í–ï–¢: —Ç–æ–ª—å–∫–æ –∏–º—è –∞–≥–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: nova)"""
    
    async def classify_agent(self, task: str) -> Dict[str, any]:
        """–ë—ã—Å—Ç—Ä–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞"""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        cache_key = task.lower().strip()
        if cache_key in self.classification_cache:
            return {
                "agent": self.classification_cache[cache_key],
                "source": "cache",
                "response_time_ms": 0,
                "cost": 0.0
            }
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        provider = self.providers[self.current_provider]
        
        # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è
        start_time = asyncio.get_event_loop().time()
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
            prompt = self.classification_prompt.format(task=task)
            
            if self.current_provider == "groq":
                agent = await self._classify_groq(prompt, provider)
            elif self.current_provider == "ollama":
                agent = await self._classify_ollama(prompt, provider)
            elif self.current_provider == "together":
                agent = await self._classify_together(prompt, provider)
            elif self.current_provider == "openai":
                agent = await self._classify_openai(prompt, provider)
            else:
                agent = "sherlock"  # Fallback
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            response_time = (asyncio.get_event_loop().time() - start_time) * 1000
            estimated_tokens = len(prompt.split()) + 1  # –ü—Ä–æ–º–ø—Ç + –æ—Ç–≤–µ—Ç
            cost = (estimated_tokens / 1000) * provider.cost_per_1k_tokens
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
            self.classification_cache[cache_key] = agent
            
            return {
                "agent": agent,
                "source": f"{provider.name}",
                "response_time_ms": round(response_time),
                "cost": round(cost, 6),
                "tokens_used": estimated_tokens
            }
            
        except Exception as e:
            # Fallback –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫—É
            return {
                "agent": self._fallback_heuristic(task),
                "source": "heuristic_fallback",
                "response_time_ms": 1,
                "cost": 0.0,
                "error": str(e)
            }
    
    async def _classify_groq(self, prompt: str, provider: SmallLLMProvider) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ Groq"""
        
        async with aiohttp.ClientSession() as session:
            headers = {
                "Authorization": f"Bearer {self._get_api_key('groq')}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": provider.model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 10,
                "temperature": 0.1
            }
            
            async with session.post(provider.api_url, json=payload, headers=headers) as response:
                data = await response.json()
                return self._extract_agent_name(data["choices"][0]["message"]["content"])
    
    async def _classify_ollama(self, prompt: str, provider: SmallLLMProvider) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ Ollama (–ª–æ–∫–∞–ª—å–Ω–æ)"""
        
        async with aiohttp.ClientSession() as session:
            payload = {
                "model": provider.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "num_predict": 10
                }
            }
            
            async with session.post(provider.api_url, json=payload) as response:
                data = await response.json()
                return self._extract_agent_name(data["response"])
    
    async def _classify_together(self, prompt: str, provider: SmallLLMProvider) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ Together AI"""
        
        # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ Groq
        return await self._classify_groq(prompt, provider)
    
    async def _classify_openai(self, prompt: str, provider: SmallLLMProvider) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ OpenAI (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)"""
        
        # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ Groq, –Ω–æ –¥—Ä—É–≥–æ–π API –∫–ª—é—á
        return await self._classify_groq(prompt, provider)
    
    def _extract_agent_name(self, response: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –∞–≥–µ–Ω—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞"""
        
        response_lower = response.lower().strip()
        
        # –°–ø–∏—Å–æ–∫ –≤–∞–ª–∏–¥–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
        valid_agents = ["nova", "sherlock", "artemis", "ada", "cipher", "warren", "viral"]
        
        # –ò—â–µ–º –ø–µ—Ä–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        for agent in valid_agents:
            if agent in response_lower:
                return agent
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return "sherlock"
    
    def _fallback_heuristic(self, task: str) -> str:
        """–≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –∫–∞–∫ fallback"""
        
        task_lower = task.lower()
        
        if any(word in task_lower for word in ["–∞–Ω–∞–ª–∏–∑", "–¥–∞–Ω–Ω—ã–µ"]):
            return "nova"
        elif any(word in task_lower for word in ["–∫–æ–Ω—Ç–µ–Ω—Ç", "—Ç–µ–∫—Å—Ç"]):
            return "artemis"
        elif any(word in task_lower for word in ["–∫–æ–¥", "–ø—Ä–æ–≥—Ä–∞–º–º"]):
            return "ada"
        else:
            return "sherlock"
    
    def _get_api_key(self, provider: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ env)"""
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏: os.getenv(f"{provider.upper()}_API_KEY")
        return "fake_api_key_for_demo"
    
    def get_provider_stats(self) -> Dict[str, Dict]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
        
        stats = {}
        for name, provider in self.providers.items():
            stats[name] = {
                "cost_per_1k_tokens": provider.cost_per_1k_tokens,
                "avg_response_time_ms": provider.avg_response_time_ms,
                "cost_per_month_1000_requests": round(provider.cost_per_1k_tokens * 50 * 30, 4),  # ~50 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å
                "suitable_for": self._get_use_cases(provider)
            }
        
        return stats
    
    def _get_use_cases(self, provider: SmallLLMProvider) -> List[str]:
        """–ü–æ–¥—Ö–æ–¥—è—â–∏–µ —Å–ª—É—á–∞–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        
        use_cases = []
        
        if provider.cost_per_1k_tokens == 0:
            use_cases.append("–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
        
        if provider.avg_response_time_ms < 300:
            use_cases.append("Real-time –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
        
        if provider.cost_per_1k_tokens < 0.0005:
            use_cases.append("–í—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã")
        
        return use_cases

# –î–µ–º–æ –±—ã—Å—Ç—Ä–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
async def demo_fast_classification():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±—ã—Å—Ç—Ä–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    
    classifier = FastAgentClassifier()
    
    print("üöÄ –î–ï–ú–û –ë–´–°–¢–†–û–ô LLM-–ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò")
    print("=" * 50)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
    test_tasks = [
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ–¥–∞–∂–∏ –∑–∞ –∫–≤–∞—Ä—Ç–∞–ª",
        "–°–æ–∑–¥–∞–π –ª–æ–≥–æ—Ç–∏–ø –¥–ª—è —Å—Ç–∞—Ä—Ç–∞–ø–∞", 
        "–ù–∞–π–¥–∏ –±–∞–≥–∏ –≤ –∫–æ–¥–µ",
        "–ó–∞–ø—É—Å—Ç–∏ —Ä–µ–∫–ª–∞–º–Ω—É—é –∫–∞–º–ø–∞–Ω–∏—é",
        "–ò–∑—É—á–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –Ω–∞ —Ä—ã–Ω–∫–µ"
    ]
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
    print("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –ü–†–û–í–ê–ô–î–ï–†–û–í:")
    stats = classifier.get_provider_stats()
    for provider, data in stats.items():
        print(f"   {provider}:")
        print(f"      üí∞ ${data['cost_per_1k_tokens']:.6f} –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤")
        print(f"      ‚ö° {data['avg_response_time_ms']}–º—Å –æ—Ç–≤–µ—Ç")
        print(f"      üìÖ ${data['cost_per_month_1000_requests']}/–º–µ—Å—è—Ü –∑–∞ 1000 –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"      üéØ {', '.join(data['suitable_for'])}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
    print(f"\nüß™ –¢–ï–°–¢–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:")
    
    for task in test_tasks:
        result = await classifier.classify_agent(task)
        
        print(f"\nüìã '{task}'")
        print(f"   ü§ñ –ê–≥–µ–Ω—Ç: {result['agent']}")
        print(f"   ‚ö° –í—Ä–µ–º—è: {result['response_time_ms']}–º—Å")
        print(f"   üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: ${result['cost']:.6f}")
        print(f"   üì° –ò—Å—Ç–æ—á–Ω–∏–∫: {result['source']}")

if __name__ == "__main__":
    asyncio.run(demo_fast_classification()) 