#!/usr/bin/env python3
"""
üé≠ Critique-Guided Improvement (CGI) - –°–∏—Å—Ç–µ–º–∞ "–∞–∫—Ç—ë—Ä-–∫—Ä–∏—Ç–∏–∫" 

–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—é:
- –ê–∫—Ç—ë—Ä –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–¥–∞—á–∏
- –ö—Ä–∏—Ç–∏–∫ –¥–∞—ë—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ  
- –°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—Ä–∏—Ç–∏–∫—É –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏–π
- –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ reinforcement learning

–ü—Ä–∏–Ω—Ü–∏–ø: "–ö—Ä–∏—Ç–∏–∫–∞ –¥–µ–ª–∞–µ—Ç –Ω–∞—Å –ª—É—á—à–µ" üéØ
"""

import asyncio
import json
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
from enum import Enum
import logging

logger = logging.getLogger(__name__)

class CritiqueType(Enum):
    """–¢–∏–ø—ã –∫—Ä–∏—Ç–∏–∫–∏"""
    PERFORMANCE = "performance"     # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    QUALITY = "quality"            # –ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    APPROACH = "approach"          # –ü–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é
    EFFICIENCY = "efficiency"      # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    USER_SATISFACTION = "user_satisfaction"  # –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

class CritiqueSeverity(Enum):
    """–°–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å –∫—Ä–∏—Ç–∏–∫–∏"""
    MINOR = "minor"        # –ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è
    MODERATE = "moderate"  # –£–º–µ—Ä–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
    MAJOR = "major"        # –°–µ—Ä—å—ë–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
    CRITICAL = "critical"  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏

@dataclass
class CritiquePoint:
    """–û—Ç–¥–µ–ª—å–Ω–∞—è —Ç–æ—á–∫–∞ –∫—Ä–∏—Ç–∏–∫–∏"""
    critique_type: CritiqueType
    severity: CritiqueSeverity
    title: str
    description: str
    evidence: str  # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã/–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
    suggestion: str  # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
    confidence: float  # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∫—Ä–∏—Ç–∏–∫–∞ (0.0-1.0)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'type': self.critique_type.value,
            'severity': self.severity.value,
            'title': self.title,
            'description': self.description,
            'evidence': self.evidence,
            'suggestion': self.suggestion,
            'confidence': self.confidence
        }

@dataclass
class TaskExecution:
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∞–∫—Ç—ë—Ä–æ–º"""
    task_id: str
    agent_id: str
    task_description: str
    input_data: Dict[str, Any]
    output_result: Any
    execution_time: float
    timestamp: datetime
    context: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'task_id': self.task_id,
            'agent_id': self.agent_id,
            'task_description': self.task_description,
            'input_data': self.input_data,
            'output_result': self.output_result,
            'execution_time': self.execution_time,
            'timestamp': self.timestamp.isoformat(),
            'context': self.context
        }

@dataclass
class DetailedCritique:
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –∫—Ä–∏—Ç–∏–∫–∞ –æ—Ç –∫—Ä–∏—Ç–∏–∫–∞"""
    execution_id: str
    critic_id: str
    overall_score: float  # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ (0.0-1.0)
    critique_points: List[CritiquePoint]
    summary: str  # –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ
    improvement_priority: str  # 'low', 'medium', 'high', 'urgent'
    estimated_impact: float  # –û–∂–∏–¥–∞–µ–º–æ–µ –≤–ª–∏—è–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π (0.0-1.0)
    timestamp: datetime
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'execution_id': self.execution_id,
            'critic_id': self.critic_id,
            'overall_score': self.overall_score,
            'critique_points': [cp.to_dict() for cp in self.critique_points],
            'summary': self.summary,
            'improvement_priority': self.improvement_priority,
            'estimated_impact': self.estimated_impact,
            'timestamp': self.timestamp.isoformat()
        }

class CriticAgent:
    """–ê–≥–µ–Ω—Ç-–∫—Ä–∏—Ç–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∞–±–æ—Ç—ã –¥—Ä—É–≥–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, critic_id: str, expertise_areas: List[str] = None):
        self.critic_id = critic_id
        self.expertise_areas = expertise_areas or []
        self.critique_history: List[DetailedCritique] = []
        self.evaluation_criteria = self._setup_evaluation_criteria()
        
        logger.info(f"üé≠ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫—Ä–∏—Ç–∏–∫ {critic_id} —Å —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–æ–π: {self.expertise_areas}")
    
    def _setup_evaluation_criteria(self) -> Dict[str, Dict]:
        """–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∫—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏"""
        return {
            'performance': {
                'execution_time': {'weight': 0.3, 'threshold': 30.0},  # —Å–µ–∫—É–Ω–¥—ã
                'success_rate': {'weight': 0.4, 'threshold': 0.8},
                'resource_usage': {'weight': 0.3, 'threshold': 0.7}
            },
            'quality': {
                'completeness': {'weight': 0.4, 'threshold': 0.9},
                'accuracy': {'weight': 0.4, 'threshold': 0.85},
                'relevance': {'weight': 0.2, 'threshold': 0.8}
            },
            'efficiency': {
                'steps_count': {'weight': 0.3, 'threshold': 10},
                'redundancy': {'weight': 0.4, 'threshold': 0.2},
                'optimization': {'weight': 0.3, 'threshold': 0.7}
            }
        }
    
    async def critique_execution(self, execution: TaskExecution) -> DetailedCritique:
        """–°–æ–∑–¥–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∫—Ä–∏—Ç–∏–∫—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏"""
        
        logger.info(f"üîç –ö—Ä–∏—Ç–∏–∫ {self.critic_id} –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ {execution.task_id}")
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        performance_points = self._analyze_performance(execution)
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_points = self._analyze_quality(execution)
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ–¥—Ö–æ–¥–∞
        approach_points = self._analyze_approach(execution)
        
        # –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        efficiency_points = self._analyze_efficiency(execution)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ –∫—Ä–∏—Ç–∏–∫–∏
        all_critique_points = performance_points + quality_points + approach_points + efficiency_points
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–π –±–∞–ª–ª
        overall_score = self._calculate_overall_score(all_critique_points)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π
        improvement_priority = self._determine_improvement_priority(all_critique_points, overall_score)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –≤–ª–∏—è–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π
        estimated_impact = self._estimate_improvement_impact(all_critique_points)
        
        # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ
        summary = self._generate_summary(all_critique_points, overall_score)
        
        critique = DetailedCritique(
            execution_id=execution.task_id,
            critic_id=self.critic_id,
            overall_score=overall_score,
            critique_points=all_critique_points,
            summary=summary,
            improvement_priority=improvement_priority,
            estimated_impact=estimated_impact,
            timestamp=datetime.now()
        )
        
        self.critique_history.append(critique)
        logger.info(f"‚úÖ –ö—Ä–∏—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: –±–∞–ª–ª {overall_score:.2f}, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç {improvement_priority}")
        
        return critique
    
    def _analyze_performance(self, execution: TaskExecution) -> List[CritiquePoint]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        points = []
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        if execution.execution_time > self.evaluation_criteria['performance']['execution_time']['threshold']:
            points.append(CritiquePoint(
                critique_type=CritiqueType.PERFORMANCE,
                severity=CritiqueSeverity.MODERATE,
                title="–ú–µ–¥–ª–µ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ",
                description=f"–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω—è–ª–∞—Å—å {execution.execution_time:.1f}—Å, —á—Ç–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è {self.evaluation_criteria['performance']['execution_time']['threshold']}—Å",
                evidence=f"execution_time: {execution.execution_time:.2f}s",
                suggestion="–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–µ—à–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –æ–ø–µ—Ä–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É",
                confidence=0.9
            ))
        
        return points
    
    def _analyze_quality(self, execution: TaskExecution) -> List[CritiquePoint]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        points = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ—Ç—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if not execution.output_result or (isinstance(execution.output_result, str) and len(execution.output_result.strip()) < 50):
            points.append(CritiquePoint(
                critique_type=CritiqueType.QUALITY,
                severity=CritiqueSeverity.MAJOR,
                title="–ù–µ–ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
                description="–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∫–∞–∂–µ—Ç—Å—è –Ω–µ–ø–æ–ª–Ω—ã–º –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–º",
                evidence=f"output_length: {len(str(execution.output_result)) if execution.output_result else 0} chars",
                suggestion="–£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –∑–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é, –¥–æ–±–∞–≤–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è",
                confidence=0.8
            ))
        
        return points
    
    def _analyze_approach(self, execution: TaskExecution) -> List[CritiquePoint]:
        """–ê–Ω–∞–ª–∏–∑ –ø–æ–¥—Ö–æ–¥–∞ –∫ —Ä–µ—à–µ–Ω–∏—é"""
        points = []
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        context = execution.context
        if 'tools_used' in context:
            tools_count = len(context['tools_used'])
            if tools_count > 10:
                points.append(CritiquePoint(
                    critique_type=CritiqueType.APPROACH,
                    severity=CritiqueSeverity.MINOR,
                    title="–ò–∑–±—ã—Ç–æ—á–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤",
                    description=f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {tools_count} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –≤–æ–∑–º–æ–∂–Ω–æ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ",
                    evidence=f"tools_used: {context['tools_used']}",
                    suggestion="–ü–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π –∑–∞—Ä–∞–Ω–µ–µ, –∏–∑–±–µ–≥–∞—Ç—å –ª–∏—à–Ω–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π",
                    confidence=0.7
                ))
        
        return points
    
    def _analyze_efficiency(self, execution: TaskExecution) -> List[CritiquePoint]:
        """–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        points = []
        
        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∫ –∫–∞—á–µ—Å—Ç–≤—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        time_quality_ratio = execution.execution_time / max(len(str(execution.output_result)), 1)
        if time_quality_ratio > 0.5:  # –ë–æ–ª—å—à–µ 0.5 —Å–µ–∫—É–Ω–¥—ã –Ω–∞ —Å–∏–º–≤–æ–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            points.append(CritiquePoint(
                critique_type=CritiqueType.EFFICIENCY,
                severity=CritiqueSeverity.MODERATE,
                title="–ù–∏–∑–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
                description=f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∫ –æ–±—ä—ë–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ: {time_quality_ratio:.3f}—Å/—Å–∏–º–≤–æ–ª",
                evidence=f"time: {execution.execution_time:.2f}s, output_length: {len(str(execution.output_result))}",
                suggestion="–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å, —É–º–µ–Ω—å—à–∏—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏",
                confidence=0.6
            ))
        
        return points
    
    def _calculate_overall_score(self, critique_points: List[CritiquePoint]) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞"""
        if not critique_points:
            return 1.0
        
        # –í—ã—á–∏—Å–ª—è–µ–º —à—Ç—Ä–∞—Ñ—ã –ø–æ —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç–∏
        penalty_weights = {
            CritiqueSeverity.MINOR: 0.05,
            CritiqueSeverity.MODERATE: 0.15,
            CritiqueSeverity.MAJOR: 0.3,
            CritiqueSeverity.CRITICAL: 0.5
        }
        
        total_penalty = 0
        for point in critique_points:
            penalty = penalty_weights[point.severity] * point.confidence
            total_penalty += penalty
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —à—Ç—Ä–∞—Ñ –º–∞–∫—Å–∏–º—É–º–æ–º 0.9 (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª 0.1)
        total_penalty = min(total_penalty, 0.9)
        
        return 1.0 - total_penalty
    
    def _determine_improvement_priority(self, critique_points: List[CritiquePoint], overall_score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π"""
        
        if overall_score < 0.4:
            return "urgent"
        elif overall_score < 0.6:
            return "high"
        elif any(point.severity == CritiqueSeverity.MAJOR for point in critique_points):
            return "medium"
        else:
            return "low"
    
    def _estimate_improvement_impact(self, critique_points: List[CritiquePoint]) -> float:
        """–û—Ü–µ–Ω–∏—Ç—å –æ–∂–∏–¥–∞–µ–º–æ–µ –≤–ª–∏—è–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π"""
        
        if not critique_points:
            return 0.0
        
        # –°—É–º–º–∏—Ä—É–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
        total_impact = 0
        for point in critique_points:
            if point.severity == CritiqueSeverity.CRITICAL:
                total_impact += 0.4 * point.confidence
            elif point.severity == CritiqueSeverity.MAJOR:
                total_impact += 0.3 * point.confidence
            elif point.severity == CritiqueSeverity.MODERATE:
                total_impact += 0.2 * point.confidence
            else:  # MINOR
                total_impact += 0.1 * point.confidence
        
        return min(total_impact, 1.0)
    
    def _generate_summary(self, critique_points: List[CritiquePoint], overall_score: float) -> str:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –∫—Ä–∏—Ç–∏–∫–∏"""
        
        if not critique_points:
            return f"–û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞! –û–±—â–∏–π –±–∞–ª–ª: {overall_score:.2f}. –ó–∞–º–µ—á–∞–Ω–∏–π –Ω–µ—Ç."
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
        by_type = {}
        for point in critique_points:
            ptype = point.critique_type.value
            if ptype not in by_type:
                by_type[ptype] = []
            by_type[ptype].append(point)
        
        summary_parts = [f"–û–±—â–∏–π –±–∞–ª–ª: {overall_score:.2f}."]
        
        for ptype, points in by_type.items():
            major_count = sum(1 for p in points if p.severity in [CritiqueSeverity.MAJOR, CritiqueSeverity.CRITICAL])
            minor_count = len(points) - major_count
            
            type_summary = f"{ptype.title()}: {major_count} —Å–µ—Ä—å—ë–∑–Ω—ã—Ö"
            if minor_count > 0:
                type_summary += f", {minor_count} –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö"
            type_summary += " –∑–∞–º–µ—á–∞–Ω–∏–π."
            
            summary_parts.append(type_summary)
        
        return " ".join(summary_parts) 