"""
üìä MetricsCollector - –°–∏—Å—Ç–µ–º–∞ —Å–±–æ—Ä–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç—Ä–∏–∫ KittyCore 3.0

–ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤:
- ‚úÖ –†–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
- ‚úÖ –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–∑–∞–¥–∞—á–∏, –∞–≥–µ–Ω—Ç—ã, —Å–∏—Å—Ç–µ–º–∞)
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤
- ‚úÖ Obsidian-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –æ—Ç—á—ë—Ç—ã
- ‚úÖ –ü—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
- ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –æ–±—É—á–µ–Ω–∏—è

–ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏–º CrewAI, LangGraph, AutoGen –ø–æ –≥–ª—É–±–∏–Ω–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏! üöÄ
"""

import asyncio
import json
import sqlite3
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union, Tuple
from pathlib import Path
import statistics
from collections import defaultdict, deque

from loguru import logger
from .obsidian_db import ObsidianDB, ObsidianNote


@dataclass
class TaskMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏"""
    task_id: str
    task_type: str
    complexity_score: Union[float, str]
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    start_time: datetime
    end_time: Optional[datetime] = None
    duration_seconds: Optional[float] = None
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤
    agents_created: int = 0
    agents_succeeded: int = 0
    agents_failed: int = 0
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    quality_score: float = 0.0
    validation_passed: bool = False
    rework_required: bool = False
    rework_attempts: int = 0
    
    # –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
    llm_requests: int = 0
    llm_tokens_used: int = 0
    files_created: int = 0
    memory_usage_mb: float = 0.0
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_satisfaction: Optional[float] = None
    human_interventions: int = 0
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['start_time'] = self.start_time.isoformat()
        if self.end_time:
            data['end_time'] = self.end_time.isoformat()
        return data
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TaskMetrics':
        data['start_time'] = datetime.fromisoformat(data['start_time'])
        if data.get('end_time'):
            data['end_time'] = datetime.fromisoformat(data['end_time'])
        return cls(**data)


@dataclass
class AgentMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞"""
    agent_id: str
    agent_type: str
    task_id: str
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    start_time: datetime
    end_time: Optional[datetime] = None
    duration_seconds: Optional[float] = None
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    status: str = "running"  # running, completed, failed, timeout
    success_rate: float = 0.0
    error_count: int = 0
    retry_count: int = 0
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    tools_used: List[str] = None
    tool_success_rate: float = 0.0
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    output_quality: float = 0.0
    user_feedback: Optional[str] = None
    
    def __post_init__(self):
        if self.tools_used is None:
            self.tools_used = []
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['start_time'] = self.start_time.isoformat()
        if self.end_time:
            data['end_time'] = self.end_time.isoformat()
        return data


@dataclass
class SystemMetrics:
    """–°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""
    timestamp: datetime
    
    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    cpu_usage: float = 0.0
    memory_usage_mb: float = 0.0
    disk_usage_mb: float = 0.0
    
    # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    active_tasks: int = 0
    active_agents: int = 0
    queue_size: int = 0
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_tasks_processed: int = 0
    total_agents_created: int = 0
    average_task_duration: float = 0.0
    success_rate: float = 0.0
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        return data


class MetricsStorage:
    """–•—Ä–∞–Ω–∏–ª–∏—â–µ –º–µ—Ç—Ä–∏–∫ –≤ SQLite"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            # –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ –∑–∞–¥–∞—á
            conn.execute("""
                CREATE TABLE IF NOT EXISTS task_metrics (
                    task_id TEXT PRIMARY KEY,
                    task_type TEXT,
                    complexity_score REAL,
                    start_time TEXT,
                    end_time TEXT,
                    duration_seconds REAL,
                    agents_created INTEGER,
                    agents_succeeded INTEGER,
                    agents_failed INTEGER,
                    quality_score REAL,
                    validation_passed BOOLEAN,
                    rework_required BOOLEAN,
                    rework_attempts INTEGER,
                    llm_requests INTEGER,
                    llm_tokens_used INTEGER,
                    files_created INTEGER,
                    memory_usage_mb REAL,
                    user_satisfaction REAL,
                    human_interventions INTEGER,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ –∞–≥–µ–Ω—Ç–æ–≤
            conn.execute("""
                CREATE TABLE IF NOT EXISTS agent_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    agent_id TEXT,
                    agent_type TEXT,
                    task_id TEXT,
                    start_time TEXT,
                    end_time TEXT,
                    duration_seconds REAL,
                    status TEXT,
                    success_rate REAL,
                    error_count INTEGER,
                    retry_count INTEGER,
                    tools_used TEXT,
                    tool_success_rate REAL,
                    output_quality REAL,
                    user_feedback TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            conn.execute("""
                CREATE TABLE IF NOT EXISTS system_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    cpu_usage REAL,
                    memory_usage_mb REAL,
                    disk_usage_mb REAL,
                    active_tasks INTEGER,
                    active_agents INTEGER,
                    queue_size INTEGER,
                    total_tasks_processed INTEGER,
                    total_agents_created INTEGER,
                    average_task_duration REAL,
                    success_rate REAL,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            conn.commit()
        
        logger.info(f"üìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {self.db_path}")
    
    def store_task_metrics(self, metrics: TaskMetrics):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–¥–∞—á–∏"""
        with sqlite3.connect(self.db_path) as conn:
            data = metrics.to_dict()
            placeholders = ', '.join(['?' for _ in data])
            columns = ', '.join(data.keys())
            
            conn.execute(
                f"INSERT OR REPLACE INTO task_metrics ({columns}) VALUES ({placeholders})",
                list(data.values())
            )
            conn.commit()
    
    def store_agent_metrics(self, metrics: AgentMetrics):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∞–≥–µ–Ω—Ç–∞"""
        with sqlite3.connect(self.db_path) as conn:
            data = metrics.to_dict()
            data['tools_used'] = json.dumps(data['tools_used'])
            
            placeholders = ', '.join(['?' for _ in data if _ != 'id'])
            columns = ', '.join([k for k in data.keys() if k != 'id'])
            
            conn.execute(
                f"INSERT INTO agent_metrics ({columns}) VALUES ({placeholders})",
                [v for k, v in data.items() if k != 'id']
            )
            conn.commit()
    
    def store_system_metrics(self, metrics: SystemMetrics):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""
        with sqlite3.connect(self.db_path) as conn:
            data = metrics.to_dict()
            placeholders = ', '.join(['?' for _ in data if _ != 'id'])
            columns = ', '.join([k for k in data.keys() if k != 'id'])
            
            conn.execute(
                f"INSERT INTO system_metrics ({columns}) VALUES ({placeholders})",
                [v for k, v in data.items() if k != 'id']
            )
            conn.commit()
    
    def get_task_metrics(self, task_id: str) -> Optional[TaskMetrics]:
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–¥–∞—á–∏"""
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute(
                "SELECT * FROM task_metrics WHERE task_id = ?",
                (task_id,)
            )
            row = cursor.fetchone()
            
            if row:
                data = dict(row)
                data.pop('created_at', None)
                return TaskMetrics.from_dict(data)
            return None
    
    def get_recent_metrics(self, hours: int = 24) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —á–∞—Å—ã"""
        since = datetime.now() - timedelta(hours=hours)
        
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            
            # –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞–¥–∞—á
            task_cursor = conn.execute(
                "SELECT * FROM task_metrics WHERE start_time >= ? ORDER BY start_time DESC",
                (since.isoformat(),)
            )
            tasks = [dict(row) for row in task_cursor.fetchall()]
            
            # –ú–µ—Ç—Ä–∏–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤
            agent_cursor = conn.execute(
                "SELECT * FROM agent_metrics WHERE start_time >= ? ORDER BY start_time DESC",
                (since.isoformat(),)
            )
            agents = [dict(row) for row in agent_cursor.fetchall()]
            
            # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            system_cursor = conn.execute(
                "SELECT * FROM system_metrics WHERE timestamp >= ? ORDER BY timestamp DESC",
                (since.isoformat(),)
            )
            system = [dict(row) for row in system_cursor.fetchall()]
            
            return {
                'tasks': tasks,
                'agents': agents,
                'system': system,
                'period_hours': hours,
                'retrieved_at': datetime.now().isoformat()
            }


class MetricsAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫ –∏ —Ç—Ä–µ–Ω–¥–æ–≤"""
    
    def __init__(self, storage: MetricsStorage):
        self.storage = storage
    
    def analyze_task_performance(self, hours: int = 24) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á"""
        metrics = self.storage.get_recent_metrics(hours)
        tasks = metrics['tasks']
        
        if not tasks:
            return {'error': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥'}
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        completed_tasks = [t for t in tasks if t['end_time']]
        durations = [t['duration_seconds'] for t in completed_tasks if t['duration_seconds']]
        quality_scores = [t['quality_score'] for t in tasks if t['quality_score'] > 0]
        
        analysis = {
            'total_tasks': len(tasks),
            'completed_tasks': len(completed_tasks),
            'success_rate': len(completed_tasks) / len(tasks) if tasks else 0,
            
            'duration_stats': {
                'average': statistics.mean(durations) if durations else 0,
                'median': statistics.median(durations) if durations else 0,
                'min': min(durations) if durations else 0,
                'max': max(durations) if durations else 0
            },
            
            'quality_stats': {
                'average': statistics.mean(quality_scores) if quality_scores else 0,
                'median': statistics.median(quality_scores) if quality_scores else 0,
                'min': min(quality_scores) if quality_scores else 0,
                'max': max(quality_scores) if quality_scores else 0
            },
            
            'complexity_distribution': self._analyze_complexity_distribution(tasks),
            'failure_analysis': self._analyze_failures(tasks),
            'trends': self._analyze_trends(tasks)
        }
        
        return analysis
    
    def _analyze_complexity_distribution(self, tasks: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á"""
        complexities = [t['complexity_score'] for t in tasks if t['complexity_score']]
        
        if not complexities:
            return {'error': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏'}
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        simple = len([c for c in complexities if c < 0.3])
        medium = len([c for c in complexities if 0.3 <= c < 0.7])
        complex = len([c for c in complexities if c >= 0.7])
        
        return {
            'simple_tasks': simple,
            'medium_tasks': medium,
            'complex_tasks': complex,
            'average_complexity': statistics.mean(complexities),
            'complexity_trend': 'increasing' if complexities[-5:] > complexities[:5] else 'stable'
        }
    
    def _analyze_failures(self, tasks: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –Ω–µ—É–¥–∞—á"""
        failed_tasks = [t for t in tasks if not t['end_time'] or t['agents_failed'] > 0]
        
        if not failed_tasks:
            return {'failure_rate': 0, 'common_issues': []}
        
        failure_rate = len(failed_tasks) / len(tasks)
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω –Ω–µ—É–¥–∞—á
        rework_tasks = len([t for t in tasks if t['rework_required']])
        quality_issues = len([t for t in tasks if t['quality_score'] < 0.5])
        
        return {
            'failure_rate': failure_rate,
            'rework_rate': rework_tasks / len(tasks),
            'quality_issues_rate': quality_issues / len(tasks),
            'common_issues': [
                '–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞' if quality_issues > 0 else None,
                '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞' if rework_tasks > 0 else None,
                '–°–±–æ–∏ –∞–≥–µ–Ω—Ç–æ–≤' if any(t['agents_failed'] > 0 for t in tasks) else None
            ]
        }
    
    def _analyze_trends(self, tasks: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤"""
        if len(tasks) < 10:
            return {'error': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤'}
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        sorted_tasks = sorted(tasks, key=lambda x: x['start_time'])
        
        # –¢—Ä–µ–Ω–¥ –∫–∞—á–µ—Å—Ç–≤–∞
        recent_quality = [t['quality_score'] for t in sorted_tasks[-5:] if t['quality_score'] > 0]
        older_quality = [t['quality_score'] for t in sorted_tasks[:5] if t['quality_score'] > 0]
        
        quality_trend = 'improving' if (
            recent_quality and older_quality and 
            statistics.mean(recent_quality) > statistics.mean(older_quality)
        ) else 'stable'
        
        # –¢—Ä–µ–Ω–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        recent_durations = [t['duration_seconds'] for t in sorted_tasks[-5:] if t['duration_seconds']]
        older_durations = [t['duration_seconds'] for t in sorted_tasks[:5] if t['duration_seconds']]
        
        performance_trend = 'improving' if (
            recent_durations and older_durations and
            statistics.mean(recent_durations) < statistics.mean(older_durations)
        ) else 'stable'
        
        return {
            'quality_trend': quality_trend,
            'performance_trend': performance_trend,
            'volume_trend': 'increasing' if len(sorted_tasks[-5:]) > len(sorted_tasks[:5]) else 'stable'
        }


class MetricsCollector:
    """
    üìä –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å —Å–±–æ—Ä–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç—Ä–∏–∫
    
    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –†–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –º–µ—Ç—Ä–∏–∫
    - –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤
    - Obsidian-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –æ—Ç—á—ë—Ç—ã
    - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –æ–±—É—á–µ–Ω–∏—è
    """
    
    def __init__(self, storage_path: str, obsidian_db: ObsidianDB = None):
        self.storage_path = storage_path
        self.obsidian_db = obsidian_db
        
        # –ö—ç—à –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        self.active_tasks: Dict[str, TaskMetrics] = {}
        self.active_agents: Dict[str, AgentMetrics] = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_tasks = 0
        self.total_agents = 0
        
        logger.info(f"üìä MetricsCollector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {storage_path}")
    
    def start_task_tracking(self, task_id: str, task_type: str, complexity_score: Union[float, str]) -> TaskMetrics:
        """–ù–∞—á–∞—Ç—å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏"""
        metrics = TaskMetrics(
            task_id=task_id,
            task_type=task_type,
            complexity_score=complexity_score,
            start_time=datetime.now()
        )
        
        self.active_tasks[task_id] = metrics
        self.total_tasks += 1
        
        logger.info(f"üìä –ù–∞—á–∞—Ç–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ {task_id} (—Å–ª–æ–∂–Ω–æ—Å—Ç—å: {complexity_score})")
        
        return metrics
    
    def finish_task_tracking(self, task_id: str, **updates) -> Optional[TaskMetrics]:
        """–ó–∞–≤–µ—Ä—à–∏—Ç—å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏"""
        if task_id not in self.active_tasks:
            logger.warning(f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö")
            return None
        
        metrics = self.active_tasks[task_id]
        metrics.end_time = datetime.now()
        metrics.duration_seconds = (metrics.end_time - metrics.start_time).total_seconds()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        for key, value in updates.items():
            if hasattr(metrics, key):
                setattr(metrics, key, value)
        
        # –°–æ–∑–¥–∞—ë–º –æ—Ç—á—ë—Ç –≤ Obsidian
        if self.obsidian_db:
            self._create_task_report(metrics)
        
        # –£–¥–∞–ª—è–µ–º –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö
        del self.active_tasks[task_id]
        
        logger.info(f"üìä –ó–∞–≤–µ—Ä—à–µ–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ {task_id} (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {metrics.duration_seconds:.1f}—Å)")
        
        return metrics
    
    def start_agent_tracking(self, agent_id: str, agent_type: str, task_id: str) -> AgentMetrics:
        """–ù–∞—á–∞—Ç—å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞"""
        metrics = AgentMetrics(
            agent_id=agent_id,
            agent_type=agent_type,
            task_id=task_id,
            start_time=datetime.now()
        )
        
        self.active_agents[agent_id] = metrics
        self.total_agents += 1
        
        logger.debug(f"üìä –ù–∞—á–∞—Ç–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ {agent_id}")
        
        return metrics
    
    def finish_agent_tracking(self, agent_id: str, **updates) -> Optional[AgentMetrics]:
        """–ó–∞–≤–µ—Ä—à–∏—Ç—å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞"""
        if agent_id not in self.active_agents:
            logger.warning(f"‚ö†Ô∏è –ê–≥–µ–Ω—Ç {agent_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö")
            return None
        
        metrics = self.active_agents[agent_id]
        metrics.end_time = datetime.now()
        metrics.duration_seconds = (metrics.end_time - metrics.start_time).total_seconds()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        for key, value in updates.items():
            if hasattr(metrics, key):
                setattr(metrics, key, value)
        
        # –£–¥–∞–ª—è–µ–º –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö
        del self.active_agents[agent_id]
        
        logger.debug(f"üìä –ó–∞–≤–µ—Ä—à–µ–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ {agent_id}")
        
        return metrics
    
    def get_current_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        return {
            'active_tasks': len(self.active_tasks),
            'active_agents': len(self.active_agents),
            'total_tasks_processed': self.total_tasks,
            'total_agents_created': self.total_agents,
            'timestamp': datetime.now().isoformat()
        }
    
    def _create_task_report(self, metrics: TaskMetrics):
        """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç –æ –∑–∞–¥–∞—á–µ –≤ Obsidian"""
        if not self.obsidian_db:
            return
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
        duration_str = f"{metrics.duration_seconds:.1f}—Å" if metrics.duration_seconds else "N/A"
        quality_str = f"{metrics.quality_score:.2f}" if metrics.quality_score else "N/A"
        
        content = f"""# –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞–¥–∞—á–∏ {metrics.task_id}

## –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
- **–¢–∏–ø –∑–∞–¥–∞—á–∏:** {metrics.task_type}
- **–°–ª–æ–∂–Ω–æ—Å—Ç—å:** {metrics.complexity_score}
- **–ù–∞—á–∞–ª–æ:** {metrics.start_time.strftime('%Y-%m-%d %H:%M:%S')}
- **–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ:** {metrics.end_time.strftime('%Y-%m-%d %H:%M:%S') if metrics.end_time else '–í –ø—Ä–æ—Ü–µ—Å—Å–µ'}
- **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {duration_str}

## –ú–µ—Ç—Ä–∏–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤
- **–°–æ–∑–¥–∞–Ω–æ –∞–≥–µ–Ω—Ç–æ–≤:** {metrics.agents_created}
- **–£—Å–ø–µ—à–Ω–æ:** {metrics.agents_succeeded}
- **–ù–µ—É–¥–∞—á–Ω–æ:** {metrics.agents_failed}
- **–£—Å–ø–µ—à–Ω–æ—Å—Ç—å:** {(metrics.agents_succeeded / max(1, metrics.agents_created) * 100):.1f}%

## –ö–∞—á–µ—Å—Ç–≤–æ
- **–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:** {quality_str}
- **–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞:** {'‚úÖ' if metrics.validation_passed else '‚ùå'}
- **–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞:** {'‚ö†Ô∏è' if metrics.rework_required else '‚úÖ'}
- **–ü–æ–ø—ã—Ç–æ–∫ –¥–æ—Ä–∞–±–æ—Ç–∫–∏:** {metrics.rework_attempts}

## –†–µ—Å—É—Ä—Å—ã
- **LLM –∑–∞–ø—Ä–æ—Å–æ–≤:** {metrics.llm_requests}
- **–¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ:** {metrics.llm_tokens_used}
- **–§–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–æ:** {metrics.files_created}
- **–ü–∞–º—è—Ç—å (–ú–ë):** {metrics.memory_usage_mb:.1f}

## –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
- **–í–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤ —á–µ–ª–æ–≤–µ–∫–∞:** {metrics.human_interventions}
- **–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç—å:** {metrics.user_satisfaction if metrics.user_satisfaction else 'N/A'}

---
*–û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ MetricsCollector*
"""
        
        note = ObsidianNote(
            title=f"–ú–µ—Ç—Ä–∏–∫–∏ –∑–∞–¥–∞—á–∏ {metrics.task_id}",
            content=content,
            tags=["–º–µ—Ç—Ä–∏–∫–∏", "–∑–∞–¥–∞—á–∞", str(metrics.task_type)],
            metadata={
                "task_id": metrics.task_id,
                "task_type": metrics.task_type,
                "complexity_score": metrics.complexity_score,
                "duration_seconds": metrics.duration_seconds,
                "quality_score": metrics.quality_score,
                "success_rate": metrics.agents_succeeded / max(1, metrics.agents_created)
            },
            folder="system/metrics"
        )
        
        self.obsidian_db.save_note(note, f"task_metrics_{metrics.task_id}.md")
        logger.info(f"üìä –°–æ–∑–¥–∞–Ω –æ—Ç—á—ë—Ç –æ –∑–∞–¥–∞—á–µ –≤ Obsidian: {metrics.task_id}")


def create_metrics_collector(storage_path: str, obsidian_db: ObsidianDB = None) -> MetricsCollector:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è MetricsCollector"""
    return MetricsCollector(storage_path, obsidian_db) 