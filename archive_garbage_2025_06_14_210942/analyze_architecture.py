#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã KittyCore 3.0 –∏ –ø–æ–∏—Å–∫ –¥—É–±–ª–∏—Ä—É—é—â–µ–≥–æ—Å—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞
"""
import os
import re
import ast
from pathlib import Path
from collections import defaultdict, Counter
from typing import Dict, List, Set, Tuple

class ArchitectureAnalyzer:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.components = defaultdict(list)
        self.duplicates = defaultdict(list)
        self.imports = defaultdict(set)
        self.classes = defaultdict(list)
        self.functions = defaultdict(list)
        self.files_analyzed = []
        
    def analyze_project(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç"""
        print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É KittyCore 3.0...")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º Python —Ñ–∞–π–ª—ã
        python_files = list(self.project_root.rglob("*.py"))
        python_files = [f for f in python_files if not any(
            exclude in str(f) for exclude in [
                "__pycache__", ".venv", "venv", "archive_", 
                "node_modules", ".git"
            ]
        )]
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(python_files)} Python —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        for file_path in python_files:
            self._analyze_python_file(file_path)
            
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
        self._generate_report()
        
    def _analyze_python_file(self, file_path: Path):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω Python —Ñ–∞–π–ª"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            self.files_analyzed.append(file_path)
            
            # –ü–∞—Ä—Å–∏–º AST
            try:
                tree = ast.parse(content)
                self._extract_ast_info(tree, file_path)
            except SyntaxError:
                print(f"‚ö†Ô∏è  –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ {file_path}")
                
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã –≤—Ä—É—á–Ω—É—é (–Ω–∞ —Å–ª—É—á–∞–π –ø—Ä–æ–±–ª–µ–º —Å AST)
            self._extract_imports_manual(content, file_path)
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ñ–∞–π–ª –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ
            self._classify_file(file_path, content)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {file_path}: {e}")
            
    def _extract_ast_info(self, tree: ast.AST, file_path: Path):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ AST"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                self.classes[node.name].append(file_path)
            elif isinstance(node, ast.FunctionDef):
                self.functions[node.name].append(file_path)
            elif isinstance(node, (ast.Import, ast.ImportFrom)):
                self._extract_import_from_node(node, file_path)
                
    def _extract_import_from_node(self, node: ast.AST, file_path: Path):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–ø–æ—Ä—Ç –∏–∑ AST —É–∑–ª–∞"""
        if isinstance(node, ast.Import):
            for alias in node.names:
                self.imports[file_path].add(alias.name)
        elif isinstance(node, ast.ImportFrom):
            module = node.module or ""
            for alias in node.names:
                full_import = f"{module}.{alias.name}" if module else alias.name
                self.imports[file_path].add(full_import)
                
    def _extract_imports_manual(self, content: str, file_path: Path):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–ø–æ—Ä—Ç—ã –≤—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è"""
        import_patterns = [
            r'^import\s+([a-zA-Z_][a-zA-Z0-9_.]*)',
            r'^from\s+([a-zA-Z_][a-zA-Z0-9_.]*)\s+import',
        ]
        
        for line in content.split('\n'):
            line = line.strip()
            for pattern in import_patterns:
                match = re.match(pattern, line)
                if match:
                    self.imports[file_path].add(match.group(1))
                    
    def _classify_file(self, file_path: Path, content: str):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º"""
        relative_path = file_path.relative_to(self.project_root)
        path_str = str(relative_path)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –ø—É—Ç–∏
        if "core/" in path_str:
            self.components["Core Components"].append(relative_path)
        elif "agents/" in path_str:
            self.components["Agent System"].append(relative_path)
        elif "tools/" in path_str:
            self.components["Tool System"].append(relative_path)
        elif "memory/" in path_str:
            self.components["Memory System"].append(relative_path)
        elif "llm/" in path_str:
            self.components["LLM Integration"].append(relative_path)
        elif "visualization/" in path_str:
            self.components["Visualization"].append(relative_path)
        elif "config/" in path_str:
            self.components["Configuration"].append(relative_path)
        elif "tests/" in path_str:
            self.components["Tests"].append(relative_path)
        elif "obsidian" in path_str:
            self.components["Obsidian Integration"].append(relative_path)
        elif "web/" in path_str:
            self.components["Web Interface"].append(relative_path)
        elif "browser" in path_str:
            self.components["Browser Tools"].append(relative_path)
        else:
            self.components["Root Level / Other"].append(relative_path)
            
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
        content_lower = content.lower()
        
        if "orchestrator" in content_lower:
            self.components["Orchestration Logic"].append(relative_path)
        if "agent" in content_lower and "class" in content_lower:
            self.components["Agent Classes"].append(relative_path)
        if "memory" in content_lower and ("store" in content_lower or "save" in content_lower):
            self.components["Memory Implementation"].append(relative_path)
        if "llm" in content_lower and ("openai" in content_lower or "anthropic" in content_lower):
            self.components["LLM Providers"].append(relative_path)
            
    def _find_duplicates(self):
        """–ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–π—Å—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª"""
        print("\nüîç –ò—â—É –¥—É–±–ª–∏—Ä—É—é—â–∏–π—Å—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª...")
        
        # –î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –∫–ª–∞—Å—Å—ã
        for class_name, files in self.classes.items():
            if len(files) > 1:
                self.duplicates[f"Class: {class_name}"].extend(files)
                
        # –î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Ñ—É–Ω–∫—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ)
        important_functions = [
            "execute", "run", "process", "create", "generate", "analyze",
            "orchestrate", "initialize", "setup", "configure", "validate"
        ]
        
        for func_name, files in self.functions.items():
            if len(files) > 1 and any(keyword in func_name.lower() for keyword in important_functions):
                self.duplicates[f"Function: {func_name}"].extend(files)
                
        # –ü–æ—Ö–æ–∂–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        file_names = defaultdict(list)
        for file_path in self.files_analyzed:
            name = file_path.stem.lower()
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è
            name = re.sub(r'[_-]', '', name)
            file_names[name].append(file_path)
            
        for name, files in file_names.items():
            if len(files) > 1:
                self.duplicates[f"Similar files: {name}"].extend(files)
                
    def _generate_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –æ–± –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ"""
        self._find_duplicates()
        
        print("\n" + "="*80)
        print("üìä –û–¢–ß–Å–¢ –û–ë –ê–†–•–ò–¢–ï–ö–¢–£–†–ï KITTYCORE 3.0")
        print("="*80)
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ Python —Ñ–∞–π–ª–æ–≤: {len(self.files_analyzed)}")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤: {len(self.classes)}")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π: {len(self.functions)}")
        print(f"  ‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {len(self.components)}")
        
        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        print(f"\nüèóÔ∏è  –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´:")
        for component, files in sorted(self.components.items()):
            if files:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
                print(f"\n  üì¶ {component} ({len(files)} —Ñ–∞–π–ª–æ–≤):")
                for file_path in sorted(files)[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                    print(f"    ‚Ä¢ {file_path}")
                if len(files) > 5:
                    print(f"    ... –∏ –µ—â—ë {len(files) - 5} —Ñ–∞–π–ª–æ–≤")
                    
        # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
        if self.duplicates:
            print(f"\nüö® –û–ë–ù–ê–†–£–ñ–ï–ù–û –î–£–ë–õ–ò–†–û–í–ê–ù–ò–ï:")
            for duplicate_type, files in self.duplicates.items():
                print(f"\n  ‚ö†Ô∏è  {duplicate_type}:")
                for file_path in sorted(set(files)):
                    rel_path = file_path.relative_to(self.project_root) if hasattr(file_path, 'relative_to') else file_path
                    print(f"    ‚Ä¢ {rel_path}")
        else:
            print(f"\n‚úÖ –ö—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!")
            
        # –¢–æ–ø –∏–º–ø–æ—Ä—Ç–æ–≤
        print(f"\nüì¶ –¢–û–ü –ò–ú–ü–û–†–¢–ò–†–£–ï–ú–´–• –ú–û–î–£–õ–ï–ô:")
        all_imports = []
        for imports in self.imports.values():
            all_imports.extend(imports)
        import_counter = Counter(all_imports)
        
        for module, count in import_counter.most_common(10):
            if count > 2:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ
                print(f"  ‚Ä¢ {module}: {count} —Ä–∞–∑")
                
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        self._generate_recommendations()
        
    def _generate_recommendations(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ:")
        
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
        if len(self.duplicates) > 5:
            recommendations.append("üîÑ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è - –Ω—É–∂–Ω–∞ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è")
            
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        root_files = len(self.components.get("Root Level / Other", []))
        if root_files > 10:
            recommendations.append(f"üìÅ {root_files} —Ñ–∞–π–ª–æ–≤ –≤ –∫–æ—Ä–Ω–µ - –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –≤ –ø–æ–¥–ø–∞–ø–∫–∏")
            
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ—Å—Ç—ã
        test_files = len(self.components.get("Tests", []))
        total_files = len(self.files_analyzed)
        if test_files < total_files * 0.3:
            recommendations.append(f"üß™ –ú–∞–ª–æ —Ç–µ—Å—Ç–æ–≤ ({test_files}/{total_files}) - –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–∫—Ä—ã—Ç–∏–µ")
            
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        for component, files in self.components.items():
            if len(files) > 20:
                recommendations.append(f"üì¶ {component} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({len(files)} —Ñ–∞–π–ª–æ–≤) - —Ä–∞–∑–¥–µ–ª–∏—Ç—å")
                
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –∏–º–µ–Ω–∞–º–∏
        duplicate_classes = sum(1 for files in self.classes.values() if len(files) > 1)
        if duplicate_classes > 3:
            recommendations.append(f"üè∑Ô∏è  {duplicate_classes} –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –∫–ª–∞—Å—Å–æ–≤ - –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å")
            
        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                print(f"  {i}. {rec}")
        else:
            print("  ‚úÖ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤—ã–≥–ª—è–¥–∏—Ç —Ö–æ—Ä–æ—à–æ!")
            
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è KittyCore
        print(f"\nüéØ –°–ü–ï–¶–ò–§–ò–ß–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø KITTYCORE 3.0:")
        print("  1. ‚úÖ –°–æ–∑–¥–∞—Ç—å –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª-–º—ç–ø–ø–µ—Ä –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤")
        print("  2. ‚úÖ –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ tool —Å–∏—Å—Ç–µ–º—ã –≤ unified_tools.py") 
        print("  3. ‚úÖ –°–æ–∑–¥–∞—Ç—å –µ–¥–∏–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è –≤—Å–µ—Ö LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤")
        print("  4. ‚úÖ –ú–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ CLI —Å–∫—Ä–∏–ø—Ç—ã –≤ kittycore/cli/")
        print("  5. ‚úÖ –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏ –≤ single_memory.py")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    analyzer = ArchitectureAnalyzer()
    analyzer.analyze_project()
    
    # –°–æ–∑–¥–∞—ë–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –≤ —Ñ–∞–π–ª
    print(f"\nüíæ –°–æ–∑–¥–∞—é –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç...")
    
    report_path = Path("ARCHITECTURE_ANALYSIS.md")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã KittyCore 3.0\n\n")
        f.write(f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {Path().cwd()}\n")
        f.write(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(analyzer.files_analyzed)}\n\n")
        
        f.write("## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã\n\n")
        for component, files in sorted(analyzer.components.items()):
            if files:
                f.write(f"### {component} ({len(files)} —Ñ–∞–π–ª–æ–≤)\n\n")
                for file_path in sorted(files):
                    f.write(f"- `{file_path}`\n")
                f.write("\n")
                
        if analyzer.duplicates:
            f.write("## –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ\n\n")
            for duplicate_type, files in analyzer.duplicates.items():
                f.write(f"### {duplicate_type}\n\n")
                for file_path in sorted(set(files)):
                    rel_path = file_path.relative_to(analyzer.project_root) if hasattr(file_path, 'relative_to') else file_path
                    f.write(f"- `{rel_path}`\n")
                f.write("\n")
                
    print(f"üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {report_path}")

if __name__ == "__main__":
    main() 