#!/usr/bin/env python3
"""
üß† –¢–ï–°–¢ A-MEM –í –ü–û–õ–ù–û–°–¢–¨–Æ OFFLINE –†–ï–ñ–ò–ú–ï

–≠—Ç–æ—Ç —Ç–µ—Å—Ç –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω–æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
–±–µ–∑ –ø–æ–ø—ã—Ç–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞.
"""

import asyncio
import sys
import time
import json
import os
from pathlib import Path
from datetime import datetime

# –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π offline —Ä–µ–∂–∏–º
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1" 
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# –£–±–∏—Ä–∞–µ–º fallback –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
if "FORCE_AMEM_FALLBACK" in os.environ:
    del os.environ["FORCE_AMEM_FALLBACK"]

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent))

from kittycore.core.unified_orchestrator import UnifiedOrchestrator, UnifiedConfig
from loguru import logger

async def test_offline_model_loading():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¢–û–õ–¨–ö–û –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ offline —Ä–µ–∂–∏–º–µ"""
    print("üöÄ === –¢–ï–°–¢ OFFLINE –ó–ê–ì–†–£–ó–ö–ò –õ–û–ö–ê–õ–¨–ù–´–• –ú–û–î–ï–õ–ï–ô ===")
    print("üîí TRANSFORMERS_OFFLINE = 1 (–ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π offline —Ä–µ–∂–∏–º)")
    
    try:
        from sentence_transformers import SentenceTransformer
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º HuggingFace –∫–µ—à
        cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
        if not cache_dir.exists():
            cache_dir = Path("hf_cache")  # –õ–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à
        
        print(f"üìÅ –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à: {cache_dir}")
        
        # –ò—â–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ –∫–µ—à–µ
        cached_models = []
        if cache_dir.exists():
            for model_dir in cache_dir.glob("models--sentence-transformers--*"):
                model_name = model_dir.name.replace("models--sentence-transformers--", "")
                cached_models.append(f"sentence-transformers/{model_name}")
        
        print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {len(cached_models)}")
        for model in cached_models:
            print(f"   üéØ {model}")
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–±–µ–∑ sentence-transformers/ –ø—Ä–µ—Ñ–∏–∫—Å–∞)
        local_models_to_try = [
            'paraphrase-MiniLM-L3-v2',
            'all-MiniLM-L6-v2',
            'all-mpnet-base-v2'
        ]
        
        for model_name in local_models_to_try:
            print(f"\nüì¶ OFFLINE —Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏: {model_name}")
            start_time = time.time()
            
            try:
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ offline –∑–∞–≥—Ä—É–∑–∫–∞
                model = SentenceTransformer(model_name, cache_folder=str(cache_dir))
                load_time = time.time() - start_time
                
                print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ OFFLINE –∑–∞ {load_time:.2f}—Å")
                print(f"   üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {model.get_sentence_embedding_dimension()}")
                
                # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
                test_texts = ["—Ç–µ—Å—Ç offline –º–æ–¥–µ–ª–∏", "–∞–≥–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ KittyCore"]
                embeddings = model.encode(test_texts)
                print(f"   üß† –≠–º–±–µ–¥–¥–∏–Ω–≥–∏: {embeddings.shape}")
                
                # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –±–ª–∏–∑–æ—Å—Ç—å
                from sentence_transformers.util import cos_sim
                similarity = cos_sim(embeddings[0], embeddings[1]).item()
                print(f"   üîó –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å: {similarity:.3f}")
                
                print(f"   üéâ OFFLINE –ú–û–î–ï–õ–¨ {model_name} –†–ê–ë–û–¢–ê–ï–¢ –ò–î–ï–ê–õ–¨–ù–û!")
                return model_name
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ offline –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
                continue
        
        print("‚ùå –ù–ò –û–î–ù–ê OFFLINE –ú–û–î–ï–õ–¨ –ù–ï –ó–ê–ì–†–£–ó–ò–õ–ê–°–¨!")
        return None
        
    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        return None

async def test_direct_chromadb():
    """–ü—Ä—è–º–æ–π —Ç–µ—Å—Ç ChromaDB —Å offline –º–æ–¥–µ–ª—å—é"""
    print("\nüöÄ === –ü–†–Ø–ú–û–ô –¢–ï–°–¢ ChromaDB –° OFFLINE –ú–û–î–ï–õ–¨–Æ ===")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–±–æ—Ç–∞—é—â—É—é offline –º–æ–¥–µ–ª—å
    working_model = await test_offline_model_loading()
    if not working_model:
        return {"success": False, "error": "No offline model available"}
    
    print(f"\nüîß === –ü–†–Ø–ú–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ChromaDB + {working_model} ===")
    
    try:
        import chromadb
        from sentence_transformers import SentenceTransformer
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ offline —Ä–µ–∂–∏–º–µ
        print("üìö –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ChromaDB...")
        client = chromadb.Client()
        
        print("üóÇÔ∏è –°–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é...")
        collection = client.create_collection(
            name="kittycore_offline_test",
            get_or_create=True
        )
        
        print(f"üß† –ó–∞–≥—Ä—É–∂–∞–µ–º offline –º–æ–¥–µ–ª—å {working_model}...")
        model = SentenceTransformer(working_model)
        
        print("‚úÖ ChromaDB + SentenceTransformer –≥–æ—Ç–æ–≤—ã!")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ + –ø–æ–∏—Å–∫
        test_memories = [
            "–ê–≥–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–ª –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ Python Flask —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö",
            "–ö–æ–º–∞–Ω–¥–∞ –∞–≥–µ–Ω—Ç–æ–≤ —Ä–µ—à–∏–ª–∞ —Å–ª–æ–∂–Ω—É—é –∑–∞–¥–∞—á—É –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö pandas –∏ numpy",
            "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ email —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é",
            "REST API —Å JWT –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω –ø–æ –ª—É—á—à–∏–º –ø—Ä–∞–∫—Ç–∏–∫–∞–º",
            "–ê–ª–≥–æ—Ä–∏—Ç–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø–æ–∫–∞–∑–∞–ª —Ç–æ—á–Ω–æ—Å—Ç—å 95% –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
        ]
        
        print(f"\nüíæ === –°–û–•–†–ê–ù–ï–ù–ò–ï {len(test_memories)} –í–û–°–ü–û–ú–ò–ù–ê–ù–ò–ô ===")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è
        for i, memory in enumerate(test_memories):
            print(f"   {i+1}. {memory[:50]}...")
            
            # –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            embedding = model.encode(memory).tolist()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ ChromaDB
            collection.add(
                documents=[memory],
                metadatas=[{
                    "agent_id": f"offline_agent_{i}",
                    "category": "development",
                    "timestamp": datetime.now().isoformat(),
                    "test_id": i
                }],
                ids=[f"offline_memory_{i}"],
                embeddings=[embedding]
            )
            
            print(f"      ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º {len(embedding)}D")
        
        print(f"\nüîç === –¢–ï–°–¢ –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –ü–û–ò–°–ö–ê ===")
        
        search_queries = [
            "–≤–µ–± —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ Flask Python",
            "–∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö pandas numpy", 
            "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è email –æ–±—Ä–∞–±–æ—Ç–∫–∞",
            "API –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è JWT REST",
            "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º"
        ]
        
        search_results = {}
        total_found = 0
        
        for query in search_queries:
            print(f"   üîç –ü–æ–∏—Å–∫: '{query}'")
            
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            query_embedding = model.encode(query).tolist()
            
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=2
            )
            
            found_count = len(results['documents'][0])
            search_results[query] = found_count
            total_found += found_count
            
            print(f"      üìä –ù–∞–π–¥–µ–Ω–æ: {found_count}")
            
            if found_count > 0:
                best_doc = results['documents'][0][0]
                best_distance = results['distances'][0][0] if 'distances' in results else 0
                print(f"      ‚ú® –õ—É—á—à–∏–π: {best_doc[:50]}... (distance: {best_distance:.3f})")
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_results = total_found / len(search_queries)
        
        print(f"\nüìà === –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê OFFLINE A-MEM ===")
        print(f"üíæ –í–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(test_memories)}")
        print(f"üîç –ü–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {len(search_queries)}")
        print(f"üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {total_found}")
        print(f"üìà –°—Ä–µ–¥–Ω–µ–µ –Ω–∞ –∑–∞–ø—Ä–æ—Å: {avg_results:.1f}")
        
        # –û—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        if avg_results >= 1.5:
            print("‚ú® –§–ï–ù–û–ú–ï–ù–ê–õ–¨–ù–û! Offline —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!")
            rating = "excellent"
        elif avg_results >= 1.0:
            print("‚úÖ –û–¢–õ–ò–ß–ù–û! Offline —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω!")
            rating = "good"
        elif avg_results >= 0.5:
            print("‚ö†Ô∏è –£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û! –ü–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —á–∞—Å—Ç–∏—á–Ω–æ")
            rating = "fair"
        else:
            print("‚ùå –ü–õ–û–•–û! Offline –ø–æ–∏—Å–∫ –Ω–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω")
            rating = "poor"
        
        return {
            "success": True,
            "model_used": working_model,
            "memories_stored": len(test_memories),
            "search_effectiveness": avg_results,
            "search_results": search_results,
            "rating": rating,
            "offline_mode": True
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä—è–º–æ–≥–æ ChromaDB —Ç–µ—Å—Ç–∞: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è offline —Ä–µ–∂–∏–º–∞"""
    try:
        print("üéØ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ A-MEM –≤ –ø–æ–ª–Ω–æ—Å—Ç—å—é offline —Ä–µ–∂–∏–º–µ...")
        print("üîí –í—Å–µ —Å–µ—Ç–µ–≤—ã–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã!")
        
        result = await test_direct_chromadb()
        
        if result["success"]:
            print("\nüéâ === OFFLINE –¢–ï–°–¢ –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û ===")
            print("üîí A-MEM —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é offline —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏!")
            print("üß† ChromaDB + SentenceTransformers —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É—é—Ç –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞!")
            print("üîç –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö!")
            print("‚ú® –°–∏—Å—Ç–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–Ω–æ–º–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É!")
        else:
            print("\nüí• === OFFLINE –¢–ï–°–¢ –ù–ï –ü–†–û–®–Å–õ ===")
            print(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error', 'Unknown error')}")
            print("üîß –¢—Ä–µ–±—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results_file = Path("amem_offline_test_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_file}")
        
        return result
        
    except Exception as e:
        print(f"\nüí• === –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê ===")
        print(f"‚ùå {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

if __name__ == "__main__":
    asyncio.run(main()) 