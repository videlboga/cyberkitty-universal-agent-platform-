#!/usr/bin/env python3
"""
üß¨ SelfImprovement - –°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è KittyCore 3.0

–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤
- –≠–≤–æ–ª—é—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤  
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –∏–∑ –æ–ø—ã—Ç–∞
- –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–æ–¥ –∑–∞–¥–∞—á–∏

–ü—Ä–∏–Ω—Ü–∏–ø: "–°–∏—Å—Ç–µ–º–∞ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —É–º–Ω–µ–µ —Å –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–µ–π" üöÄ
"""

import json
import time
import hashlib
import asyncio
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import logging
import random
from enum import Enum

# === –ù–û–í–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ –î–õ–Ø –ü–†–û–î–í–ò–ù–£–¢–û–ô –°–ò–°–¢–ï–ú–´ –û–ë–†–ê–¢–ù–û–ô –°–í–Ø–ó–ò ===

@dataclass
class FeedbackEntry:
    """–ó–∞–ø–∏—Å—å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
    agent_id: str
    task_id: str
    feedback_type: str  # 'success', 'failure', 'quality', 'performance'
    score: float  # 0.0 - 1.0
    context: Dict[str, Any]
    user_feedback: Optional[str] = None
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()

@dataclass
class LearningPattern:
    """–ü–∞—Ç—Ç–µ—Ä–Ω –æ–±—É—á–µ–Ω–∏—è"""
    pattern_id: str
    description: str
    triggers: List[str]  # –ß—Ç–æ –≤—ã–∑—ã–≤–∞–µ—Ç —ç—Ç–æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω
    actions: List[str]   # –ö–∞–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω—É–∂–Ω–æ –ø—Ä–µ–¥–ø—Ä–∏–Ω—è—Ç—å
    success_rate: float
    usage_count: int = 0
    
class FeedbackLoop:
    """–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.feedback_history: List[FeedbackEntry] = []
        self.learning_patterns: Dict[str, LearningPattern] = {}
        self.performance_trends: Dict[str, List[float]] = {}
        self.quality_threshold = 0.7  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞
        
    async def record_feedback(self, task_id: str, feedback_type: str, 
                            score: float, context: Dict[str, Any],
                            user_feedback: Optional[str] = None):
        """–ó–∞–ø–∏—Å–∞—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å"""
        
        feedback = FeedbackEntry(
            agent_id=self.agent_id,
            task_id=task_id,
            feedback_type=feedback_type,
            score=score,
            context=context,
            user_feedback=user_feedback
        )
        
        self.feedback_history.append(feedback)
        
        # –û–±–Ω–æ–≤–∏—Ç—å —Ç—Ä–µ–Ω–¥—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if feedback_type not in self.performance_trends:
            self.performance_trends[feedback_type] = []
        self.performance_trends[feedback_type].append(score)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ç—Ä–µ–Ω–¥–æ–≤
        if len(self.performance_trends[feedback_type]) > 100:
            self.performance_trends[feedback_type] = self.performance_trends[feedback_type][-100:]
            
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        await self._detect_learning_patterns(feedback)
        
        logger.info(f"üîÑ –ó–∞–ø–∏—Å–∞–Ω–∞ –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å: {feedback_type}={score:.2f} –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}")
        
    async def _detect_learning_patterns(self, feedback: FeedbackEntry):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 10 –∑–∞–ø–∏—Å–µ–π
        recent_feedback = self.feedback_history[-10:]
        
        if len(recent_feedback) < 5:
            return
            
        # –ü–∞—Ç—Ç–µ—Ä–Ω: –°–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞
        if feedback.feedback_type == 'quality':
            recent_scores = [f.score for f in recent_feedback if f.feedback_type == 'quality']
            if len(recent_scores) >= 3:
                trend = sum(recent_scores[-3:]) / 3
                if trend < self.quality_threshold:
                    pattern_id = f"quality_degradation_{feedback.agent_id}"
                    if pattern_id not in self.learning_patterns:
                        self.learning_patterns[pattern_id] = LearningPattern(
                            pattern_id=pattern_id,
                            description="–°–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞",
                            triggers=["low_quality_score", "user_complaints"],
                            actions=["retrain_model", "adjust_parameters", "review_data"],
                            success_rate=0.0
                        )
                        logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω —Å–Ω–∏–∂–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ {self.agent_id}")
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω: –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –æ—à–∏–±–∫–∏
        error_contexts = [f.context.get('error_type') for f in recent_feedback 
                         if f.feedback_type == 'failure' and 'error_type' in f.context]
        
        if error_contexts:
            from collections import Counter
            error_counts = Counter(error_contexts)
            for error_type, count in error_counts.items():
                if count >= 3:  # –û–¥–Ω–∞ –∏ —Ç–∞ –∂–µ –æ—à–∏–±–∫–∞ 3+ —Ä–∞–∑
                    pattern_id = f"recurring_error_{error_type}"
                    if pattern_id not in self.learning_patterns:
                        self.learning_patterns[pattern_id] = LearningPattern(
                            pattern_id=pattern_id,
                            description=f"–ü–æ–≤—Ç–æ—Ä—è—é—â–∞—è—Å—è –æ—à–∏–±–∫–∞: {error_type}",
                            triggers=[f"error_type:{error_type}"],
                            actions=["create_error_handler", "update_training", "add_validation"],
                            success_rate=0.0
                        )
                        logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –æ—à–∏–±–æ–∫: {error_type}")
    
    def get_improvement_recommendations(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
        
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        for metric, scores in self.performance_trends.items():
            if len(scores) >= 5:
                recent_avg = sum(scores[-5:]) / 5
                overall_avg = sum(scores) / len(scores)
                
                if recent_avg < overall_avg * 0.9:  # –°–Ω–∏–∂–µ–Ω–∏–µ –Ω–∞ 10%+
                    recommendations.append({
                        'type': 'performance_decline',
                        'metric': metric,
                        'severity': 'high' if recent_avg < overall_avg * 0.8 else 'medium',
                        'description': f"–°–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –º–µ—Ç—Ä–∏–∫–µ {metric}",
                        'actions': [
                            '–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö',
                            '–û–±–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å –∞–≥–µ–Ω—Ç–∞',
                            '–ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã'
                        ]
                    })
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        for pattern in self.learning_patterns.values():
            if pattern.usage_count > 0 and pattern.success_rate < 0.5:
                recommendations.append({
                    'type': 'pattern_based',
                    'pattern_id': pattern.pattern_id,
                    'severity': 'high',
                    'description': pattern.description,
                    'actions': pattern.actions
                })
        
        return recommendations
    
    def get_learning_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—É—á–µ–Ω–∏—è"""
        
        if not self.feedback_history:
            return {'total_feedback': 0, 'avg_score': 0.0, 'trends': {}}
        
        total_feedback = len(self.feedback_history)
        avg_score = sum(f.score for f in self.feedback_history) / total_feedback
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        feedback_by_type = {}
        for feedback in self.feedback_history:
            if feedback.feedback_type not in feedback_by_type:
                feedback_by_type[feedback.feedback_type] = []
            feedback_by_type[feedback.feedback_type].append(feedback.score)
        
        type_stats = {}
        for ftype, scores in feedback_by_type.items():
            type_stats[ftype] = {
                'count': len(scores),
                'avg_score': sum(scores) / len(scores),
                'trend': 'improving' if len(scores) >= 2 and scores[-1] > scores[0] else 'stable'
            }
        
        return {
            'total_feedback': total_feedback,
            'avg_score': avg_score,
            'feedback_types': type_stats,
            'patterns_detected': len(self.learning_patterns),
            'last_feedback': self.feedback_history[-1].timestamp.isoformat() if self.feedback_history else None
        }

logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetric:
    """–ú–µ—Ç—Ä–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞"""
    name: str
    value: float
    timestamp: datetime
    context: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'name': self.name,
            'value': self.value,
            'timestamp': self.timestamp.isoformat(),
            'context': self.context
        }

@dataclass
class ImprovementAction:
    """–î–µ–π—Å—Ç–≤–∏–µ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∞–≥–µ–Ω—Ç–∞"""
    action_type: str  # 'prompt_optimization', 'tool_creation', 'parameter_tuning'
    description: str
    implementation: str  # –ö–æ–¥ –∏–ª–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    expected_improvement: float
    timestamp: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

class PerformanceTracker:
    """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞"""
    
    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.metrics: List[PerformanceMetric] = []
        self.baseline_metrics: Dict[str, float] = {}
        
    def record_metric(self, name: str, value: float, context: Dict[str, Any] = None):
        """–ó–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        metric = PerformanceMetric(
            name=name,
            value=value,
            timestamp=datetime.now(),
            context=context or {}
        )
        self.metrics.append(metric)
        
        # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        if name not in self.baseline_metrics:
            self.baseline_metrics[name] = value
            
        logger.info(f"üìä –ú–µ—Ç—Ä–∏–∫–∞ {name}: {value} (–±–∞–∑–æ–≤–∞—è: {self.baseline_metrics[name]})")
        
    def get_improvement_rate(self, metric_name: str, window_size: int = 10) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏"""
        recent_metrics = [m for m in self.metrics[-window_size:] if m.name == metric_name]
        
        if len(recent_metrics) < 2:
            return 0.0
            
        baseline = self.baseline_metrics.get(metric_name, recent_metrics[0].value)
        current = recent_metrics[-1].value
        
        return (current - baseline) / baseline if baseline != 0 else 0.0
        
    def get_performance_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–¥–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        summary = {}
        
        for metric_name in self.baseline_metrics.keys():
            improvement = self.get_improvement_rate(metric_name)
            recent_values = [m.value for m in self.metrics[-5:] if m.name == metric_name]
            
            summary[metric_name] = {
                'baseline': self.baseline_metrics[metric_name],
                'current': recent_values[-1] if recent_values else 0,
                'improvement_rate': improvement,
                'trend': 'improving' if improvement > 0.05 else 'stable' if improvement > -0.05 else 'declining'
            }
            
        return summary

class ToolCreator:
    """–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∞–≥–µ–Ω—Ç–æ–º"""
    
    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.created_tools: List[Dict[str, Any]] = []
        
    def analyze_need_for_tool(self, task_context: Dict[str, Any]) -> Optional[str]:
        """–ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ
        error_patterns = task_context.get('errors', [])
        repeated_tasks = task_context.get('repeated_tasks', [])
        
        if len(error_patterns) > 3:
            return f"error_handler_for_{hashlib.md5(str(error_patterns).encode()).hexdigest()[:8]}"
            
        if len(repeated_tasks) > 5:
            return f"automation_tool_for_{hashlib.md5(str(repeated_tasks).encode()).hexdigest()[:8]}"
            
        return None
        
    def create_tool(self, tool_name: str, purpose: str, implementation: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç"""
        
        tool = {
            'name': tool_name,
            'purpose': purpose,
            'implementation': implementation,
            'created_at': datetime.now().isoformat(),
            'usage_count': 0,
            'effectiveness_score': 0.0
        }
        
        self.created_tools.append(tool)
        logger.info(f"üõ†Ô∏è –°–æ–∑–¥–∞–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {tool_name} –¥–ª—è {purpose}")
        
        return tool
        
    def suggest_tool_improvements(self, tool_name: str) -> List[str]:
        """–ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        
        tool = next((t for t in self.created_tools if t['name'] == tool_name), None)
        if not tool:
            return []
            
        suggestions = []
        
        if tool['usage_count'] > 10 and tool['effectiveness_score'] < 0.7:
            suggestions.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
            
        if tool['usage_count'] > 50:
            suggestions.append("–î–æ–±–∞–≤–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã")
            
        return suggestions

class SelfOptimizer:
    """–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞"""
    
    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.optimization_history: List[ImprovementAction] = []
        
    def analyze_performance_gaps(self, performance_summary: Dict[str, Any]) -> List[str]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        
        gaps = []
        
        for metric_name, data in performance_summary.items():
            if data['trend'] == 'declining':
                gaps.append(f"–°–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ {metric_name}")
                
            if data['improvement_rate'] < 0.1:  # –ú–µ–Ω–µ–µ 10% —É–ª—É—á—à–µ–Ω–∏—è
                gaps.append(f"–ú–µ–¥–ª–µ–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –≤ {metric_name}")
                
        return gaps
        
    def generate_improvement_plan(self, gaps: List[str], context: Dict[str, Any]) -> List[ImprovementAction]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ —É–ª—É—á—à–µ–Ω–∏–π"""
        
        actions = []
        
        for gap in gaps:
            if "—Å–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏" in gap.lower():
                action = ImprovementAction(
                    action_type="parameter_tuning",
                    description=f"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {gap}",
                    implementation="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤",
                    expected_improvement=0.15,
                    timestamp=datetime.now()
                )
                actions.append(action)
                
            elif "–º–µ–¥–ª–µ–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ" in gap.lower():
                action = ImprovementAction(
                    action_type="prompt_optimization",
                    description=f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è: {gap}",
                    implementation="–†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤",
                    expected_improvement=0.20,
                    timestamp=datetime.now()
                )
                actions.append(action)
                
        return actions
        
    def implement_improvement(self, action: ImprovementAction) -> bool:
        """–†–µ–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏—è"""
        
        try:
            logger.info(f"üîß –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏—è: {action.description}")
            
            # –ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π
            # –ü–æ–∫–∞ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
            
            self.optimization_history.append(action)
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —É–ª—É—á—à–µ–Ω–∏—è: {e}")
            return False

class SelfImprovingAgent:
    """–°–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—â–∏–π—Å—è –∞–≥–µ–Ω—Ç"""
    
    def __init__(self, agent_id: str, base_agent: Any):
        self.agent_id = agent_id
        self.base_agent = base_agent
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏
        self.performance_tracker = PerformanceTracker(agent_id)
        self.tool_creator = ToolCreator(agent_id)
        self.self_optimizer = SelfOptimizer(agent_id)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏
        self.evaluation_interval = 10  # –ö–∞–∂–¥—ã–µ 10 –∑–∞–¥–∞—á
        self.task_counter = 0
        
        logger.info(f"üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—â–∏–π—Å—è –∞–≥–µ–Ω—Ç: {agent_id}")
        
    def run_with_self_improvement(self, task: str, context: Dict[str, Any] = None) -> Any:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞—á—É —Å —Å–∞–º–æ–æ—Ü–µ–Ω–∫–æ–π –∏ —É–ª—É—á—à–µ–Ω–∏–µ–º"""
        
        start_time = time.time()
        context = context or {}
        
        try:
            # –í—ã–ø–æ–ª–Ω–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é –∑–∞–¥–∞—á—É
            result = self.base_agent.run(task)
            
            # –ó–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            execution_time = time.time() - start_time
            self.performance_tracker.record_metric(
                "execution_time", 
                execution_time,
                {"task": task, "success": True}
            )
            
            # –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
            quality_score = self._evaluate_result_quality(result, task)
            self.performance_tracker.record_metric(
                "quality_score",
                quality_score,
                {"task": task, "result_length": len(str(result))}
            )
            
            self.task_counter += 1
            
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∞ –∏ —É–ª—É—á—à–µ–Ω–∏–µ
            if self.task_counter % self.evaluation_interval == 0:
                self._perform_self_evaluation(context)
                
            return result
            
        except Exception as e:
            # –ó–∞–ø–∏—Å–∞—Ç—å –æ—à–∏–±–∫—É –∫–∞–∫ –º–µ—Ç—Ä–∏–∫—É
            self.performance_tracker.record_metric(
                "error_rate",
                1.0,
                {"task": task, "error": str(e)}
            )
            
            # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
            tool_name = self.tool_creator.analyze_need_for_tool({
                'errors': [str(e)],
                'task': task
            })
            
            if tool_name:
                self.tool_creator.create_tool(
                    tool_name,
                    f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Ç–∏–ø–∞: {type(e).__name__}",
                    f"try-except –±–ª–æ–∫ –¥–ª—è {type(e).__name__}"
                )
                
            raise
            
    def _evaluate_result_quality(self, result: Any, task: str) -> float:
        """–ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        result_str = str(result)
        if "mock response" in result_str.lower() or "hello from kittycore" in result_str.lower():
            # –î–ª—è –º–æ–∫–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –≤–∞—Ä–∏–∞—Ü–∏—é –≤–æ–∫—Ä—É–≥ –±–∞–∑–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
            return 0.4 + random.uniform(-0.1, 0.1)  # 0.3-0.5 –¥–∏–∞–ø–∞–∑–æ–Ω
        
        # –ë–∞–∑–æ–≤–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        if result is None:
            return 0.0
            
        # –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ (–Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π)
        length_score = min(len(result_str) / 100, 1.0) if len(result_str) < 1000 else 0.8
        
        # –ù–∞–ª–∏—á–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
        structure_score = 0.8 if any(char in result_str for char in ['\n', '.', ',']) else 0.5
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        content_score = 0.9 if len(result_str.split()) > 10 else 0.6
        
        return (length_score + structure_score + content_score) / 3
        
    def _perform_self_evaluation(self, context: Dict[str, Any]):
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å–∞–º–æ–æ—Ü–µ–Ω–∫—É –∏ —É–ª—É—á—à–µ–Ω–∏–µ"""
        
        logger.info(f"üîç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏ –∞–≥–µ–Ω—Ç–∞ {self.agent_id}")
        
        # –ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–¥–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        performance_summary = self.performance_tracker.get_performance_summary()
        
        # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã
        gaps = self.self_optimizer.analyze_performance_gaps(performance_summary)
        
        if gaps:
            logger.info(f"üìâ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–µ–ª—ã –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {gaps}")
            
            # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π
            improvement_plan = self.self_optimizer.generate_improvement_plan(gaps, context)
            
            # –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —É–ª—É—á—à–µ–Ω–∏—è
            for action in improvement_plan:
                success = self.self_optimizer.implement_improvement(action)
                if success:
                    logger.info(f"‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ: {action.description}")
                    
        else:
            logger.info("‚ú® –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–∞ —Å—Ç–∞–±–∏–ª—å–Ω–∞")
            
    def get_self_improvement_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç—á—ë—Ç –æ —Å–∞–º–æ–æ—Ü–µ–Ω–∫–µ"""
        
        return {
            'agent_id': self.agent_id,
            'task_count': self.task_counter,
            'performance_summary': self.performance_tracker.get_performance_summary(),
            'created_tools': len(self.tool_creator.created_tools),
            'optimizations_applied': len(self.self_optimizer.optimization_history),
            'last_evaluation': datetime.now().isoformat()
        }

# –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—â–∏—Ö—Å—è –∞–≥–µ–Ω—Ç–æ–≤
def create_self_improving_agent(agent_id: str, base_agent: Any) -> SelfImprovingAgent:
    """–°–æ–∑–¥–∞—Ç—å —Å–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—â–µ–≥–æ—Å—è –∞–≥–µ–Ω—Ç–∞"""
    return SelfImprovingAgent(agent_id, base_agent)

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏
    
    class MockAgent:
        def run(self, task: str) -> str:
            return f"–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∑–∞–¥–∞—á–∏: {task}"
    
    # –°–æ–∑–¥–∞—Ç—å —Å–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—â–µ–≥–æ—Å—è –∞–≥–µ–Ω—Ç–∞
    base_agent = MockAgent()
    smart_agent = create_self_improving_agent("demo_agent", base_agent)
    
    # –í—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    for i in range(15):
        result = smart_agent.run_with_self_improvement(f"–ó–∞–¥–∞—á–∞ {i+1}")
        print(f"–ó–∞–¥–∞—á–∞ {i+1}: {result}")
        
    # –ü–æ–ª—É—á–∏—Ç—å –æ—Ç—á—ë—Ç –æ —Å–∞–º–æ–æ—Ü–µ–Ω–∫–µ
    report = smart_agent.get_self_improvement_report()
    print("\nüìä –û—Ç—á—ë—Ç –æ —Å–∞–º–æ–æ—Ü–µ–Ω–∫–µ:")
    print(json.dumps(report, indent=2, ensure_ascii=False))

@dataclass
class PerformanceMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞"""
    agent_id: str
    task_count: int = 0
    success_rate: float = 0.0
    avg_duration: float = 0.0
    efficiency_score: float = 0.0
    last_updated: datetime = None

class PerformanceAnalytics:
    """–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤"""
    
    def __init__(self):
        self.metrics: Dict[str, PerformanceMetrics] = {}
        self.task_history: List[Dict] = []
    
    def record_task_result(self, agent_id: str, task: str, duration: float, success: bool):
        """–ó–∞–ø–∏—Å–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏"""
        if agent_id not in self.metrics:
            self.metrics[agent_id] = PerformanceMetrics(agent_id=agent_id)
        
        metrics = self.metrics[agent_id]
        metrics.task_count += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
        old_success_rate = metrics.success_rate
        metrics.success_rate = (old_success_rate * (metrics.task_count - 1) + (1.0 if success else 0.0)) / metrics.task_count
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è
        old_avg = metrics.avg_duration
        metrics.avg_duration = (old_avg * (metrics.task_count - 1) + duration) / metrics.task_count
        
        # –í—ã—á–∏—Å–ª—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        metrics.efficiency_score = metrics.success_rate * (1.0 / max(0.1, metrics.avg_duration))
        metrics.last_updated = datetime.now()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.task_history.append({
            "agent_id": agent_id,
            "task": task,
            "duration": duration,
            "success": success,
            "timestamp": datetime.now().isoformat()
        })

    def get_top_performers(self, limit: int = 5) -> List[PerformanceMetrics]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        sorted_metrics = sorted(
            self.metrics.values(),
            key=lambda m: m.efficiency_score,
            reverse=True
        )
        return sorted_metrics[:limit]
    
    def get_improvement_suggestions(self, agent_id: str) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∞–≥–µ–Ω—Ç–∞"""
        if agent_id not in self.metrics:
            return ["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"]
        
        metrics = self.metrics[agent_id]
        suggestions = []
        
        if metrics.success_rate < 0.8:
            suggestions.append("–£–ª—É—á—à–∏—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á")
        
        if metrics.avg_duration > 10.0:
            suggestions.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
        
        if metrics.task_count < 5:
            suggestions.append("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –±–æ–ª—å—à–µ –ø—Ä–∞–∫—Ç–∏–∫–∏")
        
        return suggestions if suggestions else ["–ê–≥–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!"]

class AgentEvolution:
    """–≠–≤–æ–ª—é—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def __init__(self, analytics: PerformanceAnalytics):
        self.analytics = analytics
        self.evolution_history: List[Dict] = []
    
    def evolve_agent(self, agent_id: str) -> Dict[str, Any]:
        """–≠–≤–æ–ª—é—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞—Ç—å –∞–≥–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –µ–≥–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if agent_id not in self.analytics.metrics:
            return {"status": "no_data", "message": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"}
        
        metrics = self.analytics.metrics[agent_id]
        suggestions = self.analytics.get_improvement_suggestions(agent_id)
        
        evolution = {
            "agent_id": agent_id,
            "before": {
                "success_rate": metrics.success_rate,
                "avg_duration": metrics.avg_duration,
                "efficiency": metrics.efficiency_score
            },
            "improvements": suggestions,
            "evolved_at": datetime.now().isoformat(),
            "status": "evolved"
        }
        
        self.evolution_history.append(evolution)
        return evolution 

class SelfImprovementEngine:
    """–û—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self):
        self.analytics = PerformanceAnalytics()
        self.evolution = AgentEvolution(self.analytics)

    async def record_task_execution(self, agent_id: str, task: str, duration: float, success: bool):
        """–ó–∞–ø–∏—Å–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏"""
        self.analytics.record_task_result(agent_id, task, duration, success)
        logger.info(f"üìä –ó–∞–ø–∏—Å–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞—á–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ {agent_id}: success={success}, duration={duration:.2f}s")

    async def auto_improve_agent(self, agent_id: str):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞"""
        evolution_result = self.evolution.evolve_agent(agent_id)
        logger.info(f"üß¨ –≠–≤–æ–ª—é—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ {agent_id}: {evolution_result}")
        return evolution_result

    def get_system_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç—á–µ—Ç –æ —Å–∏—Å—Ç–µ–º–µ"""
        top_performers = self.analytics.get_top_performers()
        
        return {
            "top_performers": [asdict(performer) for performer in top_performers],
            "total_agents": len(self.analytics.metrics),
            "report_time": datetime.now().isoformat()
        }

# === –°–ò–°–¢–ï–ú–ê –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ì–û –°–û–ó–î–ê–ù–ò–Ø –î–ê–¢–ê–°–ï–¢–û–í ===

@dataclass
class DatasetExample:
    """–ü—Ä–∏–º–µ—Ä –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –æ–±—É—á–µ–Ω–∏—è"""
    input_data: Dict[str, Any]
    expected_output: Any
    actual_output: Any
    quality_score: float
    context: Dict[str, Any]
    timestamp: datetime
    
    def to_training_format(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        return {
            'input': self.input_data,
            'output': self.expected_output,
            'quality': self.quality_score,
            'context': self.context
        }

class AutoDatasetCreator:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏–∑ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
    
    def __init__(self, agent_id: str, min_quality_score: float = 0.8):
        self.agent_id = agent_id
        self.min_quality_score = min_quality_score
        self.high_quality_examples: List[DatasetExample] = []
        self.failure_examples: List[DatasetExample] = []
        self.edge_case_examples: List[DatasetExample] = []
        
    async def process_feedback_for_dataset(self, feedback: FeedbackEntry, 
                                         input_data: Dict[str, Any],
                                         actual_output: Any,
                                         expected_output: Any = None):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        
        # –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä
        example = DatasetExample(
            input_data=input_data,
            expected_output=expected_output or actual_output,
            actual_output=actual_output,
            quality_score=feedback.score,
            context=feedback.context,
            timestamp=feedback.timestamp
        )
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä
        if feedback.score >= self.min_quality_score:
            self.high_quality_examples.append(example)
            logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä (score: {feedback.score:.2f})")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
            if len(self.high_quality_examples) > 1000:
                # –£–¥–∞–ª–∏—Ç—å —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ –ø—Ä–∏–º–µ—Ä—ã
                self.high_quality_examples = sorted(
                    self.high_quality_examples, 
                    key=lambda x: x.quality_score, 
                    reverse=True
                )[:800]
                
        elif feedback.score < 0.3:
            self.failure_examples.append(example)
            logger.warning(f"‚ùå –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–∏–º–µ—Ä –æ—à–∏–±–∫–∏ (score: {feedback.score:.2f})")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä
            if len(self.failure_examples) > 200:
                self.failure_examples = self.failure_examples[-150:]
                
        else:
            # –°—Ä–µ–¥–Ω–∏–µ –ø—Ä–∏–º–µ—Ä—ã –º–æ–≥—É—Ç –±—ã—Ç—å edge cases
            self.edge_case_examples.append(example)
            
            if len(self.edge_case_examples) > 300:
                self.edge_case_examples = self.edge_case_examples[-200:]
    
    def get_few_shot_examples(self, max_examples: int = 5) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è few-shot –ø—Ä–æ–º–ø—Ç–∏–Ω–≥–∞"""
        
        if not self.high_quality_examples:
            return []
        
        # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∏ –≤–∑—è—Ç—å –ª—É—á—à–∏–µ
        best_examples = sorted(
            self.high_quality_examples,
            key=lambda x: x.quality_score,
            reverse=True
        )[:max_examples]
        
        return [example.to_training_format() for example in best_examples]
    
    def create_training_dataset(self) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        
        return {
            'agent_id': self.agent_id,
            'created_at': datetime.now().isoformat(),
            'high_quality_examples': [ex.to_training_format() for ex in self.high_quality_examples],
            'failure_examples': [ex.to_training_format() for ex in self.failure_examples],
            'edge_case_examples': [ex.to_training_format() for ex in self.edge_case_examples],
            'statistics': {
                'total_examples': len(self.high_quality_examples) + len(self.failure_examples) + len(self.edge_case_examples),
                'high_quality_count': len(self.high_quality_examples),
                'failure_count': len(self.failure_examples),
                'edge_case_count': len(self.edge_case_examples),
                'avg_quality_score': sum(ex.quality_score for ex in self.high_quality_examples) / len(self.high_quality_examples) if self.high_quality_examples else 0
            }
        }
    
    def get_dataset_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        
        total_examples = len(self.high_quality_examples) + len(self.failure_examples) + len(self.edge_case_examples)
        
        if total_examples == 0:
            return {'status': 'empty', 'total_examples': 0}
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤
        all_examples = self.high_quality_examples + self.failure_examples + self.edge_case_examples
        recent_examples = [ex for ex in all_examples if (datetime.now() - ex.timestamp).days <= 7]
        
        return {
            'status': 'active',
            'total_examples': total_examples,
            'high_quality_ratio': len(self.high_quality_examples) / total_examples,
            'failure_ratio': len(self.failure_examples) / total_examples,
            'recent_examples_count': len(recent_examples),
            'avg_quality_overall': sum(ex.quality_score for ex in all_examples) / total_examples,
            'ready_for_training': len(self.high_quality_examples) >= 10,  # –ú–∏–Ω–∏–º—É–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            'last_update': max(ex.timestamp for ex in all_examples).isoformat() if all_examples else None
        }

# === –°–ò–°–¢–ï–ú–ê REAL-TIME –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –ò –ê–î–ê–ü–¢–ê–¶–ò–ò ===

@dataclass
class AlertRule:
    """–ü—Ä–∞–≤–∏–ª–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–ª–µ—Ä—Ç–æ–≤"""
    rule_id: str
    name: str
    condition: str  # 'performance_drop', 'error_spike', 'quality_decline'
    threshold: float
    severity: str  # 'low', 'medium', 'high', 'critical'
    enabled: bool = True

@dataclass
class SystemAlert:
    """–°–∏—Å—Ç–µ–º–Ω—ã–π –∞–ª–µ—Ä—Ç"""
    alert_id: str
    rule_id: str
    message: str
    severity: str
    agent_id: str
    data: Dict[str, Any]
    timestamp: datetime
    acknowledged: bool = False

class RealTimeMonitor:
    """Real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.alert_rules: Dict[str, AlertRule] = {}
        self.active_alerts: List[SystemAlert] = []
        self.metrics_buffer: Dict[str, List[float]] = {}
        self.baseline_metrics: Dict[str, float] = {}
        self.monitoring_window = 10  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∏–∑–º–µ—Ä–µ–Ω–∏–π
        
        # –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –±–∞–∑–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∞–ª–µ—Ä—Ç–æ–≤
        self._setup_default_alert_rules()
    
    def _setup_default_alert_rules(self):
        """–ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∞–ª–µ—Ä—Ç–æ–≤"""
        
        self.alert_rules = {
            'performance_drop': AlertRule(
                rule_id='performance_drop',
                name='–°–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏',
                condition='performance_drop',
                threshold=0.15,  # 15% —Å–Ω–∏–∂–µ–Ω–∏–µ
                severity='high'
            ),
            'error_spike': AlertRule(
                rule_id='error_spike',
                name='–í—Å–ø–ª–µ—Å–∫ –æ—à–∏–±–æ–∫',
                condition='error_spike', 
                threshold=0.3,  # 30% –æ—à–∏–±–æ–∫
                severity='critical'
            ),
            'quality_decline': AlertRule(
                rule_id='quality_decline',
                name='–°–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞',
                condition='quality_decline',
                threshold=0.7,  # –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∏–∂–µ 70%
                severity='medium'
            )
        }
    
    async def record_metric(self, metric_name: str, value: float):
        """–ó–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        
        if metric_name not in self.metrics_buffer:
            self.metrics_buffer[metric_name] = []
            
        self.metrics_buffer[metric_name].append(value)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞
        if len(self.metrics_buffer[metric_name]) > self.monitoring_window:
            self.metrics_buffer[metric_name] = self.metrics_buffer[metric_name][-self.monitoring_window:]
            
        # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É
        if metric_name not in self.baseline_metrics:
            self.baseline_metrics[metric_name] = value
        else:
            # –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –±–∞–∑–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ)
            alpha = 0.1
            self.baseline_metrics[metric_name] = (
                alpha * value + (1 - alpha) * self.baseline_metrics[metric_name]
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–ª–µ—Ä—Ç—ã
        await self._check_alerts(metric_name, value)
    
    async def _check_alerts(self, metric_name: str, current_value: float):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å–ª–æ–≤–∏—è –∞–ª–µ—Ä—Ç–æ–≤"""
        
        if len(self.metrics_buffer[metric_name]) < 3:
            return  # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
            
        recent_values = self.metrics_buffer[metric_name]
        baseline = self.baseline_metrics[metric_name]
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞–∂–¥–æ–µ –ø—Ä–∞–≤–∏–ª–æ
        for rule in self.alert_rules.values():
            if not rule.enabled:
                continue
                
            alert_triggered = False
            alert_data = {}
            
            if rule.condition == 'performance_drop':
                # –°–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                recent_avg = sum(recent_values[-3:]) / 3
                if baseline > 0 and (baseline - recent_avg) / baseline >= rule.threshold:
                    alert_triggered = True
                    alert_data = {
                        'baseline': baseline,
                        'current_avg': recent_avg,
                        'drop_percentage': (baseline - recent_avg) / baseline
                    }
                    
            elif rule.condition == 'error_spike':
                # –í—Å–ø–ª–µ—Å–∫ –æ—à–∏–±–æ–∫ (–¥–ª—è –º–µ—Ç—Ä–∏–∫ –æ—à–∏–±–æ–∫)
                if 'error' in metric_name.lower() or 'failure' in metric_name.lower():
                    recent_avg = sum(recent_values[-3:]) / 3
                    if recent_avg >= rule.threshold:
                        alert_triggered = True
                        alert_data = {
                            'error_rate': recent_avg,
                            'threshold': rule.threshold
                        }
                        
            elif rule.condition == 'quality_decline':
                # –°–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞
                if 'quality' in metric_name.lower():
                    recent_avg = sum(recent_values[-3:]) / 3
                    if recent_avg <= rule.threshold:
                        alert_triggered = True
                        alert_data = {
                            'quality_score': recent_avg,
                            'threshold': rule.threshold
                        }
            
            if alert_triggered:
                await self._create_alert(rule, alert_data)
    
    async def _create_alert(self, rule: AlertRule, data: Dict[str, Any]):
        """–°–æ–∑–¥–∞—Ç—å –∞–ª–µ—Ä—Ç"""
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–µ—Ç –ª–∏ —É–∂–µ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–ª–µ—Ä—Ç–∞ –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–∞–≤–∏–ª–∞
        existing_alert = next(
            (alert for alert in self.active_alerts 
             if alert.rule_id == rule.rule_id and not alert.acknowledged),
            None
        )
        
        if existing_alert:
            return  # –ê–ª–µ—Ä—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            
        alert = SystemAlert(
            alert_id=f"alert_{rule.rule_id}_{int(time.time())}",
            rule_id=rule.rule_id,
            message=f"{rule.name}: {data}",
            severity=rule.severity,
            agent_id=self.agent_id,
            data=data,
            timestamp=datetime.now()
        )
        
        self.active_alerts.append(alert)
        logger.warning(f"üö® –ê–õ–ï–†–¢ [{rule.severity.upper()}]: {alert.message}")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –ø–æ –∞–ª–µ—Ä—Ç–∞–º
        await self._handle_alert_actions(alert)
    
    async def _handle_alert_actions(self, alert: SystemAlert):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –ø–æ –∞–ª–µ—Ä—Ç–∞–º"""
        
        if alert.severity == 'critical':
            # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∞–ª–µ—Ä—Ç—ã —Ç—Ä–µ–±—É—é—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è
            logger.critical(f"üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ê–õ–ï–†–¢ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ {self.agent_id}: {alert.message}")
            
        elif alert.severity == 'high':
            # –í—ã—Å–æ–∫–∏–µ –∞–ª–µ—Ä—Ç—ã - –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É
            logger.error(f"‚ö†Ô∏è –í–´–°–û–ö–ò–ô –ê–õ–ï–†–¢ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ {self.agent_id}: {alert.message}")
            
    def acknowledge_alert(self, alert_id: str):
        """–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∞–ª–µ—Ä—Ç"""
        
        for alert in self.active_alerts:
            if alert.alert_id == alert_id:
                alert.acknowledged = True
                logger.info(f"‚úÖ –ê–ª–µ—Ä—Ç {alert_id} –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω")
                break
    
    def get_monitoring_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        
        active_alerts_count = len([a for a in self.active_alerts if not a.acknowledged])
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –º–µ—Ç—Ä–∏–∫
        metric_trends = {}
        for metric_name, values in self.metrics_buffer.items():
            if len(values) >= 3:
                recent_trend = 'stable'
                if values[-1] > values[-3] * 1.1:
                    recent_trend = 'improving'
                elif values[-1] < values[-3] * 0.9:
                    recent_trend = 'declining'
                    
                metric_trends[metric_name] = {
                    'trend': recent_trend,
                    'current': values[-1],
                    'baseline': self.baseline_metrics.get(metric_name, 0),
                    'buffer_size': len(values)
                }
        
        return {
            'agent_id': self.agent_id,
            'status': 'healthy' if active_alerts_count == 0 else 'issues_detected',
            'active_alerts': active_alerts_count,
            'total_alerts': len(self.active_alerts),
            'monitored_metrics': list(self.metrics_buffer.keys()),
            'metric_trends': metric_trends,
            'alert_rules_count': len(self.alert_rules),
            'last_check': datetime.now().isoformat()
        } 

# === –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô –î–í–ò–ñ–û–ö –°–ê–ú–û–û–ë–£–ß–ï–ù–ò–Ø 3.0 ===

class SelfLearningEngine:
    """üß† –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è —Å feedback loops –∏ real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"""
    
    def __init__(self):
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.feedback_loops: Dict[str, FeedbackLoop] = {}
        self.dataset_creators: Dict[str, AutoDatasetCreator] = {}
        self.monitors: Dict[str, RealTimeMonitor] = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã
        self.total_feedback_processed = 0
        self.total_patterns_detected = 0
        self.total_improvements_made = 0
        self.system_health_score = 1.0
        
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω SelfLearningEngine 3.0")
    
    def get_or_create_agent_components(self, agent_id: str) -> tuple[FeedbackLoop, AutoDatasetCreator, RealTimeMonitor]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –∞–≥–µ–Ω—Ç–∞"""
        
        if agent_id not in self.feedback_loops:
            self.feedback_loops[agent_id] = FeedbackLoop(agent_id)
            self.dataset_creators[agent_id] = AutoDatasetCreator(agent_id)
            self.monitors[agent_id] = RealTimeMonitor(agent_id)
            logger.info(f"üîß –°–æ–∑–¥–∞–Ω—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–∞ {agent_id}")
        
        return (
            self.feedback_loops[agent_id],
            self.dataset_creators[agent_id], 
            self.monitors[agent_id]
        )
    
    async def record_agent_execution(self, agent_id: str, task_id: str, 
                                   input_data: Dict[str, Any], output: Any,
                                   execution_time: float, success: bool,
                                   quality_score: float = None,
                                   user_feedback: str = None):
        """üîÑ –ó–∞–ø–∏—Å–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        
        feedback_loop, dataset_creator, monitor = self.get_or_create_agent_components(agent_id)
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        if not success:
            feedback_type = 'failure'
            score = 0.0
        elif quality_score is not None:
            feedback_type = 'quality'
            score = quality_score
        else:
            feedback_type = 'success'
            score = 1.0 if success else 0.0
        
        # –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = {
            'execution_time': execution_time,
            'task_complexity': len(str(input_data)),  # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
            'output_length': len(str(output)),
            'timestamp': datetime.now().isoformat()
        }
        
        if not success and 'error' in str(output).lower():
            context['error_type'] = 'execution_error'
        
        # –ó–∞–ø–∏—Å–∞—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        await feedback_loop.record_feedback(
            task_id=task_id,
            feedback_type=feedback_type,
            score=score,
            context=context,
            user_feedback=user_feedback
        )
        
        # –û–±–Ω–æ–≤–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç
        await dataset_creator.process_feedback_for_dataset(
            feedback=FeedbackEntry(
                agent_id=agent_id,
                task_id=task_id,
                feedback_type=feedback_type,
                score=score,
                context=context,
                user_feedback=user_feedback
            ),
            input_data=input_data,
            actual_output=output
        )
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫
        await monitor.record_metric('success_rate', 1.0 if success else 0.0)
        await monitor.record_metric('execution_time', execution_time)
        if quality_score is not None:
            await monitor.record_metric('quality_score', quality_score)
        
        self.total_feedback_processed += 1
        
        # –û–±–Ω–æ–≤–∏—Ç—å —Å—á–µ—Ç—á–∏–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        patterns_before = len(feedback_loop.learning_patterns)
        # patterns_after –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ feedback_loop
        
        logger.info(f"üìù –ó–∞–ø–∏—Å–∞–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ {agent_id}: {feedback_type}={score:.2f}")
    
    async def get_agent_improvement_plan(self, agent_id: str) -> Dict[str, Any]:
        """üìä –ü–æ–ª—É—á–∏—Ç—å –ø–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π –¥–ª—è –∞–≥–µ–Ω—Ç–∞"""
        
        if agent_id not in self.feedback_loops:
            return {'status': 'no_data', 'message': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'}
        
        feedback_loop = self.feedback_loops[agent_id]
        dataset_creator = self.dataset_creators[agent_id]
        monitor = self.monitors[agent_id]
        
        # –°–æ–±—Ä–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = feedback_loop.get_improvement_recommendations()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        learning_stats = feedback_loop.get_learning_statistics()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
        dataset_stats = dataset_creator.get_dataset_statistics()
        
        # –°—Ç–∞—Ç—É—Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        monitoring_status = monitor.get_monitoring_status()
        
        # Few-shot –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤
        few_shot_examples = dataset_creator.get_few_shot_examples(max_examples=3)
        
        return {
            'agent_id': agent_id,
            'status': 'analyzed',
            'recommendations': recommendations,
            'learning_statistics': learning_stats,
            'dataset_statistics': dataset_stats,
            'monitoring_status': monitoring_status,
            'few_shot_examples': few_shot_examples,
            'improvement_priority': self._calculate_improvement_priority(
                learning_stats, dataset_stats, monitoring_status
            ),
            'generated_at': datetime.now().isoformat()
        }
    
    def _calculate_improvement_priority(self, learning_stats: Dict, dataset_stats: Dict, 
                                      monitoring_status: Dict) -> str:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π"""
        
        # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        if monitoring_status['active_alerts'] > 0:
            return 'high'
        
        if learning_stats.get('avg_score', 1.0) < 0.6:
            return 'high'
            
        # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        if not dataset_stats.get('ready_for_training', False):
            return 'medium'
            
        if learning_stats.get('patterns_detected', 0) > 0:
            return 'medium'
        
        # –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        return 'low'
    
    async def auto_improve_all_agents(self) -> Dict[str, Any]:
        """üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤"""
        
        improvements = {}
        total_improved = 0
        
        for agent_id in self.feedback_loops.keys():
            try:
                improvement_plan = await self.get_agent_improvement_plan(agent_id)
                
                if improvement_plan['status'] == 'analyzed':
                    priority = improvement_plan['improvement_priority']
                    
                    if priority in ['high', 'medium']:
                        # –í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è
                        applied_improvements = await self._apply_auto_improvements(agent_id, improvement_plan)
                        improvements[agent_id] = {
                            'priority': priority,
                            'applied': applied_improvements,
                            'status': 'improved'
                        }
                        total_improved += 1
                    else:
                        improvements[agent_id] = {
                            'priority': priority,
                            'status': 'no_action_needed'
                        }
                        
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ –∞–≥–µ–Ω—Ç–∞ {agent_id}: {e}")
                improvements[agent_id] = {
                    'status': 'error',
                    'error': str(e)
                }
        
        self.total_improvements_made += total_improved
        
        return {
            'total_agents_analyzed': len(improvements),
            'total_agents_improved': total_improved,
            'improvements': improvements,
            'system_health': self._calculate_system_health(),
            'timestamp': datetime.now().isoformat()
        }
    
    async def _apply_auto_improvements(self, agent_id: str, improvement_plan: Dict[str, Any]) -> List[str]:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è"""
        
        applied = []
        
        # –û–±–Ω–æ–≤–∏—Ç—å few-shot –ø—Ä–∏–º–µ—Ä—ã
        few_shot_examples = improvement_plan.get('few_shot_examples', [])
        if few_shot_examples:
            applied.append('updated_few_shot_examples')
            logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω—ã few-shot –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∞–≥–µ–Ω—Ç–∞ {agent_id}")
        
        # –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∞–ª–µ—Ä—Ç—ã –Ω–∏–∑–∫–æ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        monitor = self.monitors[agent_id]
        for alert in monitor.active_alerts:
            if alert.severity in ['low', 'medium'] and not alert.acknowledged:
                monitor.acknowledge_alert(alert.alert_id)
                applied.append(f'acknowledged_alert_{alert.rule_id}')
        
        return applied
    
    def _calculate_system_health(self) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â–µ–µ –∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã"""
        
        if not self.feedback_loops:
            return 1.0
        
        total_score = 0
        agent_count = 0
        
        for agent_id, feedback_loop in self.feedback_loops.items():
            stats = feedback_loop.get_learning_statistics()
            agent_score = stats.get('avg_score', 0.5)
            
            # –£—á–µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –∞–ª–µ—Ä—Ç—ã
            monitor = self.monitors.get(agent_id)
            if monitor:
                active_alerts = monitor.get_monitoring_status()['active_alerts']
                if active_alerts > 0:
                    agent_score *= 0.8  # –°–Ω–∏–∑–∏—Ç—å –æ—Ü–µ–Ω–∫—É –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∞–ª–µ—Ä—Ç–æ–≤
            
            total_score += agent_score
            agent_count += 1
        
        self.system_health_score = total_score / agent_count if agent_count > 0 else 1.0
        return self.system_health_score
    
    def get_system_overview(self) -> Dict[str, Any]:
        """üìà –ü–æ–ª—É—á–∏—Ç—å –æ–±–∑–æ—Ä –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è"""
        
        total_agents = len(self.feedback_loops)
        total_datasets = len(self.dataset_creators)
        total_monitoring = len(self.monitors)
        
        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_feedback = sum(len(fl.feedback_history) for fl in self.feedback_loops.values())
        total_patterns = sum(len(fl.learning_patterns) for fl in self.feedback_loops.values())
        total_alerts = sum(len(m.active_alerts) for m in self.monitors.values())
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
        total_examples = sum(
            len(dc.high_quality_examples) + len(dc.failure_examples) + len(dc.edge_case_examples)
            for dc in self.dataset_creators.values()
        )
        
        return {
            'system_status': 'healthy' if self.system_health_score > 0.7 else 'needs_attention',
            'system_health_score': round(self.system_health_score, 3),
            'agents': {
                'total': total_agents,
                'with_feedback': len([fl for fl in self.feedback_loops.values() if fl.feedback_history]),
                'with_datasets': len([dc for dc in self.dataset_creators.values() if dc.high_quality_examples]),
                'monitored': total_monitoring
            },
            'feedback': {
                'total_processed': total_feedback,
                'patterns_detected': total_patterns,
                'active_alerts': total_alerts
            },
            'datasets': {
                'total_examples': total_examples,
                'agents_ready_for_training': len([
                    dc for dc in self.dataset_creators.values() 
                    if len(dc.high_quality_examples) >= 10
                ])
            },
            'performance': {
                'total_improvements_made': self.total_improvements_made,
                'avg_feedback_per_agent': round(total_feedback / total_agents, 1) if total_agents > 0 else 0
            },
            'last_updated': datetime.now().isoformat()
        } 